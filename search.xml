<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[吴恩达深度学习-神经网络和深度学习-第三周：Planar data classification with one hidden layer]]></title>
    <url>%2F2018%2F06%2F04%2F180604-%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%AC%AC%E4%B8%89%E5%91%A8%EF%BC%9APlanar%20data%20classification%20with%20one%20hidden%20layer%2F</url>
    <content type="text"><![CDATA[Planar data classification with one hidden layer本练习会建立只有一个隐藏层的神经网络，我们将看到这与逻辑回归有多大的差别。 You will learn how to: 用一个隐藏层的神经网络实现二分类 在神经元上使用非线性激活函数, such as tanh 计算交叉熵代价函数 实现正向传播和反向传播 1 - PackagesLet’s first import all the packages that you will need during this assignment. numpy is the fundamental package for scientific computing with Python. sklearn provides simple and efficient tools for data mining and data analysis. matplotlib is a library for plotting graphs in Python. testCases provides some test examples to assess the correctness of your functions planar_utils provide various useful functions used in this assignment 123456789101112# Package importsimport numpy as npimport matplotlib.pyplot as pltfrom testCases import *import sklearnimport sklearn.datasetsimport sklearn.linear_modelfrom planar_utils import plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets%matplotlib inlinenp.random.seed(1) # set a seed so that the results are consistent 2 - Dataset首先，让我们来获取数据集。 123X, Y = load_planar_dataset() # 作业提供的函数，感兴趣自信查看源码X.shape, Y.shape# ((2, 400), (1, 400)) 12# Visualize the data:plt.scatter(X[0, :], X[1, :], c=Y.flatten(), s=40, cmap='rainbow'); You have: - a numpy-array (matrix) X that contains your features (x1, x2) - a numpy-array (vector) Y that contains your labels (red:0, blue:1). 123456789### START CODE HERE ### (≈ 3 lines of code)shape_X = X.shapeshape_Y = Y.shapem = shape_X[1] # training set size### END CODE HERE ###print ('The shape of X is: ' + str(shape_X))print ('The shape of Y is: ' + str(shape_Y))print ('I have m = %d training examples!' % (m)) The shape of X is: (2, 400) The shape of Y is: (1, 400) I have m = 400 training examples! Expected Output:​ shape of X (2, 400) shape of Y (1, 400) m 400 3 - Simple Logistic Regression在构造神经网络前，首先来看看逻辑回归在这个问题的表现。 1234# Train the logistic regression classifierclf = sklearn.linear_model.LogisticRegressionCV();# 传入逻辑回归中的话，X和Y 要把每条样本按行排列clf.fit(X.T, Y.T); D:\Anaconda3\envs\Tensorflow\lib\site-packages\sklearn\utils\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel(). y = column_or_1d(y, warn=True) 123456789# Plot the decision boundary for logistic regressionplot_decision_boundary(lambda x: clf.predict(x), X, Y)plt.title("Logistic Regression")# Print accuracyLR_predictions = clf.predict(X.T)# 前一项计算预测正样本正确的数量，后一项计算预测负样本正确的数量。print ('Accuracy of logistic regression: %d ' % float((np.dot(Y,LR_predictions) + np.dot(1-Y,1-LR_predictions))/float(Y.size)*100) + '% ' + "(percentage of correctly labelled datapoints)") Accuracy of logistic regression: 47 % (percentage of correctly labelled datapoints) ​ Expected Output: Accuracy 47% 本数据集是非线性可分的，所有逻辑回归变现不好。接下来看看神经网络的表现。 4 - Neural Network modelLogistic regression did not work well on the “flower dataset”. You are going to train a Neural Network with a single hidden layer. Here is our model: Mathematically: For one example $x^{(i)}$:$$z^{[1] (i)} = W^{[1]} x^{(i)} + b^{[1] (i)}\tag{1}$$$$a^{[1] (i)} = \tanh(z^{[1] (i)})\tag{2}$$$$z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2] (i)}\tag{3}$$$$\hat{y}^{(i)} = a^{[2] (i)} = \sigma(z^{ [2] (i)})\tag{4}$$$$y^{(i)}_{prediction} = \begin{cases} 1 &amp; \mbox{if } a^{2} &gt; 0.5 \ 0 &amp; \mbox{otherwise } \end{cases}\tag{5}$$ Given the predictions on all the examples, you can also compute the cost $J$ as follows:$$J = - \frac{1}{m} \sum\limits_{i = 0}^{m} \large\left(\small y^{(i)}\log\left(a^{[2] (i)}\right) + (1-y^{(i)})\log\left(1- a^{[2] (i)}\right) \large \right) \small \tag{6}$$ Reminder: The general methodology to build a Neural Network is to: 1. Define the neural network structure ( # of input units, # of hidden units, etc). 2. Initialize the model&apos;s parameters 3. Loop: - Implement forward propagation - Compute loss - Implement backward propagation to get the gradients - Update parameters (gradient descent) You often build helper functions to compute steps 1-3 and then merge them into one function we call nn_model(). Once you’ve built nn_model() and learnt the right parameters, you can make predictions on new data. 4.1 - Defining the neural network structureExercise: Define three variables: - n_x: the size of the input layer - n_h: the size of the hidden layer (set this to 4) - n_y: the size of the output layer Hint: Use shapes of X and Y to find n_x and n_y. Also, hard code the hidden layer size to be 4. 12345678910111213141516171819# GRADED FUNCTION: layer_sizesdef layer_sizes(X, Y): """ Arguments: X -- input dataset of shape (input size, number of examples) Y -- labels of shape (output size, number of examples) Returns: n_x -- the size of the input layer n_h -- the size of the hidden layer n_y -- the size of the output layer """ ### START CODE HERE ### (≈ 3 lines of code) n_x = X.shape[0] # size of input layer n_h = 4 # (set this to 4) n_y = Y.shape[0] # size of output layer ### END CODE HERE ### return (n_x, n_h, n_y) 12345X_assess, Y_assess = layer_sizes_test_case()(n_x, n_h, n_y) = layer_sizes(X_assess, Y_assess)print("The size of the input layer is: n_x = " + str(n_x))print("The size of the hidden layer is: n_h = " + str(n_h))print("The size of the output layer is: n_y = " + str(n_y)) The size of the input layer is: n_x = 5 The size of the hidden layer is: n_h = 4 The size of the output layer is: n_y = 2 Expected Output (these are not the sizes you will use for your network, they are just used to assess the function you’ve just coded). n_x 5 n_h 4 n_y 2 4.2 - Initialize the model’s parametersExercise: Implement the function initialize_parameters(). Instructions: Make sure your parameters’ sizes are right. Refer to the neural network figure above if needed. You will initialize the weights matrices with random values. Use: np.random.randn(a,b) * 0.01 to randomly initialize a matrix of shape (a,b). You will initialize the bias vectors as zeros. Use: np.zeros((a,b)) to initialize a matrix of shape (a,b) with zeros. 12345678910111213141516171819202122232425262728293031323334353637# GRADED FUNCTION: initialize_parametersdef initialize_parameters(n_x, n_h, n_y): """ Argument: n_x -- size of the input layer n_h -- size of the hidden layer n_y -- size of the output layer Returns: params -- python dictionary containing your parameters: W1 -- weight matrix of shape (n_h, n_x) b1 -- bias vector of shape (n_h, 1) W2 -- weight matrix of shape (n_y, n_h) b2 -- bias vector of shape (n_y, 1) """ np.random.seed(2) # we set up a seed so that your output matches ours although the initialization is random. ### START CODE HERE ### (≈ 4 lines of code) W1 = np.random.randn(n_h, n_x) * 0.01 b1 = np.zeros((n_h, 1)) W2 = np.random.randn(n_y, n_h) * 0.01 b2 = np.zeros((n_y, 1)) ### END CODE HERE ### assert (W1.shape == (n_h, n_x)) assert (b1.shape == (n_h, 1)) assert (W2.shape == (n_y, n_h)) assert (b2.shape == (n_y, 1)) parameters = &#123;"W1": W1, "b1": b1, "W2": W2, "b2": b2&#125; return parameters 1234567n_x, n_h, n_y = initialize_parameters_test_case()parameters = initialize_parameters(n_x, n_h, n_y)print("W1 = " + str(parameters["W1"]))print("b1 = " + str(parameters["b1"]))print("W2 = " + str(parameters["W2"]))print("b2 = " + str(parameters["b2"])) W1 = [[-0.00416758 -0.00056267] [-0.02136196 0.01640271] [-0.01793436 -0.00841747] [ 0.00502881 -0.01245288]] b1 = [[0.] [0.] [0.] [0.]] W2 = [[-0.01057952 -0.00909008 0.00551454 0.02292208]] b2 = [[0.]] Expected Output: W1 [[-0.00416758 -0.00056267] [-0.02136196 0.01640271] [-0.01793436 -0.00841747] [ 0.00502881 -0.01245288]] b1 [[ 0.] [ 0.] [ 0.] [ 0.]] W2 [[-0.01057952 -0.00909008 0.00551454 0.02292208]] b2 [[ 0.]] 4.3 - The LoopQuestion: Implement forward_propagation(). Instructions: Look above at the mathematical representation of your classifier. You can use the function sigmoid(). It is built-in (imported) in the notebook. You can use the function np.tanh(). It is part of the numpy library. The steps you have to implement are: Retrieve each parameter from the dictionary “parameters” (which is the output of initialize_parameters()) by using parameters[&quot;..&quot;]. Implement Forward Propagation. Compute $Z^{[1]}, A^{[1]}, Z^{[2]}$ and $A^{[2]}$ (the vector of all your predictions on all the examples in the training set). Values needed in the backpropagation are stored in “cache“. The cache will be given as an input to the backpropagation function. 123456789101112131415161718192021222324252627282930313233343536# GRADED FUNCTION: forward_propagationdef forward_propagation(X, parameters): """ Argument: X -- input data of size (n_x, m) parameters -- python dictionary containing your parameters (output of initialization function) Returns: A2 -- The sigmoid output of the second activation cache -- a dictionary containing "Z1", "A1", "Z2" and "A2" """ # Retrieve each parameter from the dictionary "parameters" ### START CODE HERE ### (≈ 4 lines of code) W1 = parameters['W1'] b1 = parameters['b1'] W2 = parameters['W2'] b2 = parameters['b2'] ### END CODE HERE ### # Implement Forward Propagation to calculate A2 (probabilities) ### START CODE HERE ### (≈ 4 lines of code) Z1 = W1 @ X + b1 A1 = np.tanh(Z1) Z2 = W2 @ A1 + b2 A2 = sigmoid(Z2) ### END CODE HERE ### assert(A2.shape == (1, X.shape[1])) cache = &#123;"Z1": Z1, "A1": A1, "Z2": Z2, "A2": A2&#125; return A2, cache 123456X_assess, parameters = forward_propagation_test_case()A2, cache = forward_propagation(X_assess, parameters)# Note: we use the mean here just to make sure that your output matches ours. print(np.mean(cache['Z1']) ,np.mean(cache['A1']),np.mean(cache['Z2']),np.mean(cache['A2'])) -0.0004997557777419902 -0.000496963353231779 0.0004381874509591466 0.500109546852431 ​ Expected Output: -0.000499755777742 -0.000496963353232 0.000438187450959 0.500109546852 Now that you have computed $A^{[2]}$ (in the Python variable “A2“), which contains $a^{2}$ for every example, you can compute the cost function as follows: $$J = - \frac{1}{m} \sum\limits_{i = 0}^{m} \large{(} \small y^{(i)}\log\left(a^{[2] (i)}\right) + (1-y^{(i)})\log\left(1- a^{[2] (i)}\right) \large{)} \small\tag{13}$$ Exercise: Implement compute_cost() to compute the value of the cost $J$. Instructions: There are many ways to implement the cross-entropy loss. To help you, we give you how we would have implemented$- \sum\limits_{i=0}^{m} y^{(i)}\log(a^{2})$:12logprobs = np.multiply(np.log(A2),Y)cost = - np.sum(logprobs) # no need to use a for loop! (you can use either np.multiply() and then np.sum() or directly np.dot()). 1234567891011121314151617181920212223242526272829# GRADED FUNCTION: compute_costdef compute_cost(A2, Y, parameters): """ Computes the cross-entropy cost given in equation (13) Arguments: A2 -- The sigmoid output of the second activation, of shape (1, number of examples) Y -- "true" labels vector of shape (1, number of examples) parameters -- python dictionary containing your parameters W1, b1, W2 and b2 Returns: cost -- cross-entropy cost given equation (13) """ m = Y.shape[1] # number of example # Compute the cross-entropy cost ### START CODE HERE ### (≈ 2 lines of code) logprobs = Y * np.log(A2) + (1 - Y) * np.log(1 - A2)# cost = -np.mean(logprobs) cost = -np.sum(logprobs) / m ### END CODE HERE ### cost = np.squeeze(cost) # makes sure cost is the dimension we expect. # E.g., turns [[17]] into 17 assert(isinstance(cost, float)) return cost 123A2, Y_assess, parameters = compute_cost_test_case()print("cost = " + str(compute_cost(A2, Y_assess, parameters))) cost = 0.6929198937761266 ​ Expected Output: cost 0.692919893776 Using the cache computed during forward propagation, you can now implement backward propagation. Question: Implement the function backward_propagation(). Instructions:Backpropagation is usually the hardest (most mathematical) part in deep learning. To help you, here again is the slide from the lecture on backpropagation. You’ll want to use the six equations on the right of this slide, since you are building a vectorized implementation. Tips: To compute dZ1 you’ll need to compute $g^{[1]’}(Z^{[1]})$. Since $g^{[1]}(.)$ is the tanh activation function, if $a = g^{[1]}(z)$ then $g^{[1]’}(z) = 1-a^2$. So you can compute$g^{[1]’}(Z^{[1]})$ using (1 - np.power(A1, 2)). 123456789101112131415161718192021222324252627282930313233343536373839404142434445# GRADED FUNCTION: backward_propagationdef backward_propagation(parameters, cache, X, Y): """ Implement the backward propagation using the instructions above. Arguments: parameters -- python dictionary containing our parameters cache -- a dictionary containing "Z1", "A1", "Z2" and "A2". X -- input data of shape (2, number of examples) Y -- "true" labels vector of shape (1, number of examples) Returns: grads -- python dictionary containing your gradients with respect to different parameters """ m = X.shape[1] # First, retrieve W1 and W2 from the dictionary "parameters". ### START CODE HERE ### (≈ 2 lines of code) W1 = parameters['W1'] W2 = parameters['W2'] ### END CODE HERE ### # Retrieve also A1 and A2 from dictionary "cache". ### START CODE HERE ### (≈ 2 lines of code) A1 = cache['A1'] A2 = cache['A2'] ### END CODE HERE ### # Backward propagation: calculate dW1, db1, dW2, db2. ### START CODE HERE ### (≈ 6 lines of code, corresponding to 6 equations on slide above) dZ2 = A2 - Y dW2 = dZ2 @ A1.T / m db2 = dZ2.sum(axis=1, keepdims=True) / m dZ1 = W2.T @ dZ2 * (1 - np.square(A1)) dW1 = dZ1 @ X.T / m db1 = dZ1.sum(axis=1, keepdims=True) / m ### END CODE HERE ### grads = &#123;"dW1": dW1, "db1": db1, "dW2": dW2, "db2": db2&#125; return grads 1234567parameters, cache, X_assess, Y_assess = backward_propagation_test_case()grads = backward_propagation(parameters, cache, X_assess, Y_assess)print ("dW1 = "+ str(grads["dW1"]))print ("db1 = "+ str(grads["db1"]))print ("dW2 = "+ str(grads["dW2"]))print ("db2 = "+ str(grads["db2"])) dW1 = [[ 0.01018708 -0.00708701] [ 0.00873447 -0.0060768 ] [-0.00530847 0.00369379] [-0.02206365 0.01535126]] db1 = [[-0.00069728] [-0.00060606] [ 0.000364 ] [ 0.00151207]] dW2 = [[ 0.00363613 0.03153604 0.01162914 -0.01318316]] db2 = [[0.06589489]] Expected output: dW1 [[ 0.01018708 -0.00708701] [ 0.00873447 -0.0060768 ] [-0.00530847 0.00369379] [-0.02206365 0.01535126]] db1 [[-0.00069728] [-0.00060606] [ 0.000364 ] [ 0.00151207]] dW2 [[ 0.00363613 0.03153604 0.01162914 -0.01318316]] db2 [[ 0.06589489]] Question: Implement the update rule. Use gradient descent. You have to use (dW1, db1, dW2, db2) in order to update (W1, b1, W2, b2). General gradient descent rule: $ \theta = \theta - \alpha \frac{\partial J }{ \partial \theta }$ where $\alpha$ is the learning rate and $\theta$ represents a parameter. Illustration: The gradient descent algorithm with a good learning rate (converging) and a bad learning rate (diverging). Images courtesy of Adam Harley. 12345678910111213141516171819202122232425262728293031323334353637383940414243# GRADED FUNCTION: update_parametersdef update_parameters(parameters, grads, learning_rate = 1.2): """ Updates parameters using the gradient descent update rule given above Arguments: parameters -- python dictionary containing your parameters grads -- python dictionary containing your gradients Returns: parameters -- python dictionary containing your updated parameters """ # Retrieve each parameter from the dictionary "parameters" ### START CODE HERE ### (≈ 4 lines of code) W1 = parameters['W1'] b1 = parameters['b1'] W2 = parameters['W2'] b2 = parameters['b2'] ### END CODE HERE ### # Retrieve each gradient from the dictionary "grads" ### START CODE HERE ### (≈ 4 lines of code) dW1 = grads['dW1'] db1 = grads['db1'] dW2 = grads['dW2'] db2 = grads['db2'] ## END CODE HERE ### # Update rule for each parameter ### START CODE HERE ### (≈ 4 lines of code) W1 -= learning_rate * dW1 b1 -= learning_rate * db1 W2 -= learning_rate * dW2 b2 -= learning_rate * db2 ### END CODE HERE ### parameters = &#123;"W1": W1, "b1": b1, "W2": W2, "b2": b2&#125; return parameters 1234567parameters, grads = update_parameters_test_case()parameters = update_parameters(parameters, grads)print("W1 = " + str(parameters["W1"]))print("b1 = " + str(parameters["b1"]))print("W2 = " + str(parameters["W2"]))print("b2 = " + str(parameters["b2"])) W1 = [[-0.00643025 0.01936718] [-0.02410458 0.03978052] [-0.01653973 -0.02096177] [ 0.01046864 -0.05990141]] b1 = [[-1.02420756e-06] [ 1.27373948e-05] [ 8.32996807e-07] [-3.20136836e-06]] W2 = [[-0.01041081 -0.04463285 0.01758031 0.04747113]] b2 = [[0.00010457]] Expected Output: W1 [[-0.00643025 0.01936718] [-0.02410458 0.03978052] [-0.01653973 -0.02096177] [ 0.01046864 -0.05990141]] b1 [[ -1.02420756e-06] [ 1.27373948e-05] [ 8.32996807e-07] [ -3.20136836e-06]] W2 [[-0.01041081 -0.04463285 0.01758031 0.04747113]] b2 [[ 0.00010457]] 4.4 - Integrate parts 4.1, 4.2 and 4.3 in nn_model()Question: Build your neural network model in nn_model(). Instructions: The neural network model has to use the previous functions in the right order. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# GRADED FUNCTION: nn_modeldef nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False): """ Arguments: X -- dataset of shape (2, number of examples) Y -- labels of shape (1, number of examples) n_h -- size of the hidden layer num_iterations -- Number of iterations in gradient descent loop print_cost -- if True, print the cost every 1000 iterations Returns: parameters -- parameters learnt by the model. They can then be used to predict. """ np.random.seed(3) n_x = layer_sizes(X, Y)[0] n_y = layer_sizes(X, Y)[2] # Initialize parameters, then retrieve W1, b1, W2, b2. Inputs: "n_x, n_h, n_y". Outputs = "W1, b1, W2, b2, parameters". ### START CODE HERE ### (≈ 5 lines of code) parameters = initialize_parameters(n_x, n_h, n_y) W1 = parameters['W1'] b1 = parameters['b1'] W2 = parameters['W2'] b2 = parameters['b2'] ### END CODE HERE ### # Loop (gradient descent) for i in range(0, num_iterations): ### START CODE HERE ### (≈ 4 lines of code) # Forward propagation. Inputs: "X, parameters". Outputs: "A2, cache". A2, cache = forward_propagation(X, parameters) # Cost function. Inputs: "A2, Y, parameters". Outputs: "cost". cost = compute_cost(A2, Y, parameters) # Backpropagation. Inputs: "parameters, cache, X, Y". Outputs: "grads". grads = backward_propagation(parameters, cache, X, Y) # Gradient descent parameter update. Inputs: "parameters, grads". Outputs: "parameters". parameters = update_parameters(parameters, grads) ### END CODE HERE ### # Print the cost every 1000 iterations if print_cost and i % 1000 == 0: print ("Cost after iteration %i: %f" %(i, cost)) return parameters 1234567X_assess, Y_assess = nn_model_test_case()parameters = nn_model(X_assess, Y_assess, 4, num_iterations=10000, print_cost=False)print("W1 = " + str(parameters["W1"]))print("b1 = " + str(parameters["b1"]))print("W2 = " + str(parameters["W2"]))print("b2 = " + str(parameters["b2"])) D:\Anaconda3\envs\Tensorflow\lib\site-packages\ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log F:\PycharmProjects\DLcode\代码作业\第一课第三周编程作业\assignment3\planar_utils.py:34: RuntimeWarning: overflow encountered in exp s = 1/(1+np.exp(-x)) W1 = [[-4.18497897 5.33206142] [-7.53803882 1.20755762] [-4.19298806 5.32617188] [ 7.53798331 -1.20758933]] b1 = [[ 2.32932918] [ 3.81001746] [ 2.33008879] [-3.81011387]] W2 = [[-6033.8235662 -6008.1429712 -6033.08779759 6008.07951848]] b2 = [[-52.67923259]] Expected Output: W1 [[-4.18494056 5.33220609] [-7.52989382 1.24306181] [-4.1929459 5.32632331] [ 7.52983719 -1.24309422]] b1 [[ 2.32926819] [ 3.79458998] [ 2.33002577] [-3.79468846]] W2 [[-6033.83672146 -6008.12980822 -6033.10095287 6008.06637269]] b2 [[-52.66607724]] 4.5 PredictionsQuestion: Use your model to predict by building predict().Use forward propagation to predict results. Reminder: predictions = $y_{prediction} = \mathbb 1 \textfalse = \begin{cases} 1 &amp; \text{if}\ activation &gt; 0.5 \ 0 &amp; \text{otherwise} \end{cases}$ As an example, if you would like to set the entries of a matrix X to 0 and 1 based on a threshold you would do: 123456789101112131415161718192021222324```python# GRADED FUNCTION: predictdef predict(parameters, X): &quot;&quot;&quot; Using the learned parameters, predicts a class for each example in X Arguments: parameters -- python dictionary containing your parameters X -- input data of size (n_x, m) Returns predictions -- vector of predictions of our model (red: 0 / blue: 1) &quot;&quot;&quot; # Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold. ### START CODE HERE ### (≈ 2 lines of code) A2, cache = forward_propagation(X, parameters) predictions = np.around(A2) # 四舍五入 ### END CODE HERE ### return predictions 1234parameters, X_assess = predict_test_case()predictions = predict(parameters, X_assess)print("predictions mean = " + str(np.mean(predictions))) predictions mean = 0.6666666666666666 ​ Expected Output: predictions mean 0.666666666667 It is time to run the model and see how it performs on a planar dataset. Run the following code to test your model with a single hidden layer of $n_h$ hidden units. 123456# Build a model with a n_h-dimensional hidden layerparameters = nn_model(X, Y, n_h = 4, num_iterations = 10000, print_cost=True)# Plot the decision boundaryplot_decision_boundary(lambda x: predict(parameters, x.T), X, Y)plt.title("Decision Boundary for hidden layer size " + str(4)) Cost after iteration 0: 0.693048 Cost after iteration 1000: 0.288083 Cost after iteration 2000: 0.254385 Cost after iteration 3000: 0.233864 Cost after iteration 4000: 0.226792 Cost after iteration 5000: 0.222644 Cost after iteration 6000: 0.219731 Cost after iteration 7000: 0.217504 Cost after iteration 8000: 0.219460 Cost after iteration 9000: 0.218608 Text(0.5,1,&apos;Decision Boundary for hidden layer size 4&apos;) Expected Output: Cost after iteration 9000 0.218607 123# Print accuracypredictions = predict(parameters, X)print ('Accuracy: %d' % float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100) + '%') Accuracy: 90% ​ Expected Output: Accuracy 90% Accuracy is really high compared to Logistic Regression. The model has learnt the leaf patterns of the flower! Neural networks are able to learn even highly non-linear decision boundaries, unlike logistic regression. Now, let’s try out several hidden layer sizes. 4.6 - Tuning hidden layer size (optional/ungraded exercise)Run the following code. It may take 1-2 minutes. You will observe different behaviors of the model for various hidden layer sizes. 123456789101112# This may take about 2 minutes to runplt.figure(figsize=(16, 32))hidden_layer_sizes = [1, 2, 3, 4, 5, 10, 20]for i, n_h in enumerate(hidden_layer_sizes): plt.subplot(5, 2, i+1) plt.title('Hidden Layer of size %d' % n_h) parameters = nn_model(X, Y, n_h, num_iterations = 5000) plot_decision_boundary(lambda x: predict(parameters, x.T), X, Y) predictions = predict(parameters, X) accuracy = float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100) print ("Accuracy for &#123;&#125; hidden units: &#123;&#125; %".format(n_h, accuracy)) Accuracy for 1 hidden units: 67.5 % Accuracy for 2 hidden units: 67.25 % Accuracy for 3 hidden units: 90.75 % Accuracy for 4 hidden units: 90.5 % Accuracy for 5 hidden units: 91.25 % Accuracy for 10 hidden units: 90.25 % Accuracy for 20 hidden units: 90.0 % Interpretation: The larger models (with more hidden units) are able to fit the training set better, until eventually the largest models overfit the data. The best hidden layer size seems to be around n_h = 5. Indeed, a value around here seems to fits the data well without also incurring noticable overfitting. You will also learn later about regularization, which lets you use very large models (such as n_h = 50) without much overfitting. Optional questions: Note: Remember to submit the assignment but clicking the blue “Submit Assignment” button at the upper-right. Some optional/ungraded questions that you can explore if you wish: What happens when you change the tanh activation for a sigmoid activation or a ReLU activation? Play with the learning_rate. What happens? What if we change the dataset? (See part 5 below!) You’ve learnt to: Build a complete neural network with a hidden layer Make a good use of a non-linear unit Implemented forward propagation and backpropagation, and trained a neural network See the impact of varying the hidden layer size, including overfitting. Nice work! 5) Performance on other datasetsIf you want, you can rerun the whole notebook (minus the dataset part) for each of the following datasets. 123456789101112131415161718192021# Datasetsnoisy_circles, noisy_moons, blobs, gaussian_quantiles, no_structure = load_extra_datasets()datasets = &#123;"noisy_circles": noisy_circles, "noisy_moons": noisy_moons, "blobs": blobs, "gaussian_quantiles": gaussian_quantiles&#125;### START CODE HERE ### (choose your dataset)dataset = "gaussian_quantiles"### END CODE HERE ###X, Y = datasets[dataset]X, Y = X.T, Y.reshape(1, Y.shape[0])# make blobs binaryif dataset == "blobs": Y = Y%2# Visualize the dataplt.scatter(X[0, :], X[1, :], c=Y.flatten(), s=40, cmap=plt.cm.Spectral); 12345parameters = nn_model(X, Y, n_h = 3, num_iterations = 10000, print_cost=True)# Plot the decision boundaryplot_decision_boundary(lambda x: predict(parameters, x.T), X, Y)plt.title("Decision Boundary for hidden layer size " + str(4)) Cost after iteration 0: 0.693147 Cost after iteration 1000: 0.134908 Cost after iteration 2000: 0.127436 Cost after iteration 3000: 0.128161 Cost after iteration 4000: 0.128443 Cost after iteration 5000: 0.101724 Cost after iteration 6000: 0.135567 Cost after iteration 7000: 0.115572 Cost after iteration 8000: 0.095704 Cost after iteration 9000: 0.123006 Text(0.5,1,&apos;Decision Boundary for hidden layer size 4&apos;)]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达深度学习-神经网络和深度学习-第二周：Logistic Regression with a Neural Network mindset]]></title>
    <url>%2F2018%2F06%2F04%2F180604-%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%AC%AC%E4%BA%8C%E5%91%A8%EF%BC%9ALogistic%20Regression%20with%20a%20Neural%20Network%20mindset%2F</url>
    <content type="text"><![CDATA[Logistic Regression with a Neural Network mindsetWelcome to your first (required) programming assignment! You will build a logistic regression classifier to recognize cats. This assignment will step you through how to do this with a Neural Network mindset, and so will also hone your intuitions about deep learning. Instructions: Do not use loops (for/while) in your code, unless the instructions explicitly ask you to do so. You will learn to: Build the general architecture of a learning algorithm, including: Initializing parameters Calculating the cost function and its gradient Using an optimization algorithm (gradient descent) Gather all three functions above into a main model function, in the right order. 1 - PackagesFirst, let’s run the cell below to import all the packages that you will need during this assignment. numpy is the fundamental package for scientific computing with Python. h5py is a common package to interact with a dataset that is stored on an H5 file. matplotlib is a famous library to plot graphs in Python. PIL and scipy are used here to test your model with your own picture at the end. 12345678import numpy as npimport matplotlib.pyplot as pltimport h5pyimport scipyfrom PIL import Imagefrom scipy import ndimage%matplotlib inline D:\Anaconda3\envs\Tensorflow\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters 2 - Overview of the Problem setProblem Statement: You are given a dataset (“data.h5”) containing: - a training set of m_train images labeled as cat (y=1) or non-cat (y=0) - a test set of m_test images labeled as cat or non-cat - each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB). Thus, each image is square (height = num_px) and (width = num_px). You will build a simple image-recognition algorithm that can correctly classify pictures as cat or non-cat. Let’s get more familiar with the dataset. Load the data by running the following code. 123456789101112131415def load_dataset(): train_dataset = h5py.File('datasets/train_catvnoncat.h5', "r") train_set_x_orig = np.array(train_dataset["train_set_x"][:]) # your train set features train_set_y_orig = np.array(train_dataset["train_set_y"][:]) # your train set labels test_dataset = h5py.File('datasets/test_catvnoncat.h5', "r") test_set_x_orig = np.array(test_dataset["test_set_x"][:]) # your test set features test_set_y_orig = np.array(test_dataset["test_set_y"][:]) # your test set labels classes = np.array(test_dataset["list_classes"][:]) # the list of classes train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0])) test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0])) return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes 12345# Loading the data (cat/non-cat)train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()train_set_x_orig.shape, train_set_y.shape, test_set_x_orig.shape, test_set_y.shape# ((209, 64, 64, 3), (1, 209), (50, 64, 64, 3), (1, 50))# train_set_x_orig每行都是一个图片，像素大小(64x64), rgb We added “_orig” at the end of image datasets (train and test) because we are going to preprocess them. After preprocessing, we will end up with train_set_x and test_set_x (the labels train_set_y and test_set_y don’t need any preprocessing). Each line of your train_set_x_orig and test_set_x_orig is an array representing an image. You can visualize an example by running the following code. Feel free also to change the index value and re-run to see other images. 12345# Example of a picture# np.suqeeze means Remove single-dimensional entries from the shape of an array.index = 25plt.imshow(train_set_x_orig[index])print ("y = " + str(train_set_y[:, index]) + ", it's a '" + classes[np.squeeze(train_set_y[:, index])].decode("utf-8") + "' picture.") y = [1], it&apos;s a &apos;cat&apos; picture. ​ Many software bugs in deep learning come from having matrix/vector dimensions that don’t fit. If you can keep your matrix/vector dimensions straight you will go a long way toward eliminating many bugs. Exercise: Find the values for: - m_train (number of training examples) - m_test (number of test examples) - num_px (= height = width of a training image) Remember that train_set_x_orig is a numpy-array of shape (m_train, num_px, num_px, 3). For instance, you can access m_train by writing train_set_x_orig.shape[0]. 1234567891011121314### START CODE HERE ### (≈ 3 lines of code)m_train = 209m_test = 50num_px = 64### END CODE HERE ###print ("Number of training examples: m_train = " + str(m_train))print ("Number of testing examples: m_test = " + str(m_test))print ("Height/Width of each image: num_px = " + str(num_px))print ("Each image is of size: (" + str(num_px) + ", " + str(num_px) + ", 3)")print ("train_set_x shape: " + str(train_set_x_orig.shape))print ("train_set_y shape: " + str(train_set_y.shape))print ("test_set_x shape: " + str(test_set_x_orig.shape))print ("test_set_y shape: " + str(test_set_y.shape)) Number of training examples: m_train = 209 Number of testing examples: m_test = 50 Height/Width of each image: num_px = 64 Each image is of size: (64, 64, 3) train_set_x shape: (209, 64, 64, 3) train_set_y shape: (1, 209) test_set_x shape: (50, 64, 64, 3) test_set_y shape: (1, 50) Expected Output for m_train, m_test and num_px: m_train 209 m_test 50 num_px 64 For convenience, you should now reshape images of shape (num_px, num_px, 3) in a numpy-array of shape (num_px $$ num_px $$ 3, 1). After this, our training (and test) dataset is a numpy-array where each column represents a flattened image. There should be m_train (respectively m_test) columns. Exercise: Reshape the training and test data sets so that images of size (num_px, num_px, 3) are flattened into single vectors of shape (num_px $$ num_px $$ 3, 1). A trick when you want to flatten a matrix X of shape (a,b,c,d) to a matrix X_flatten of shape (b$$c$$d, a) is to use:1X_flatten = X.reshape(X.shape[0], -1).T # X.T is the transpose of X 123456789101112# Reshape the training and test examples### START CODE HERE ### (≈ 2 lines of code)train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).Ttest_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T### END CODE HERE ###print ("train_set_x_flatten shape: " + str(train_set_x_flatten.shape))print ("train_set_y shape: " + str(train_set_y.shape))print ("test_set_x_flatten shape: " + str(test_set_x_flatten.shape))print ("test_set_y shape: " + str(test_set_y.shape))print ("sanity check after reshaping: " + str(train_set_x_flatten[0:5,0])) train_set_x_flatten shape: (12288, 209) train_set_y shape: (1, 209) test_set_x_flatten shape: (12288, 50) test_set_y shape: (1, 50) sanity check after reshaping: [17 31 56 22 33] Expected Output: train_set_x_flatten shape (12288, 209) train_set_y shape (1, 209) test_set_x_flatten shape (12288, 50) test_set_y shape (1, 50) sanity check after reshaping [17 31 56 22 33] To represent color images, the red, green and blue channels (RGB) must be specified for each pixel, and so the pixel value is actually a vector of three numbers ranging from 0 to 255. One common preprocessing step in machine learning is to center and standardize your dataset, meaning that you substract the mean of the whole numpy array from each example, and then divide each example by the standard deviation of the whole numpy array. But for picture datasets, it is simpler and more convenient and works almost as well to just divide every row of the dataset by 255 (the maximum value of a pixel channel). During the training of your model, you’re going to multiply weights and add biases to some initial inputs in order to observe neuron activations. Then you backpropogate with the gradients to train the model. But, it is extremely important for each feature to have a similar range such that our gradients don’t explode. You will see that more in detail later in the lectures. Let’s standardize our dataset. 12train_set_x = train_set_x_flatten/255.test_set_x = test_set_x_flatten/255. What you need to remember: Common steps for pre-processing a new dataset are: Figure out the dimensions and shapes of the problem (m_train, m_test, num_px, …) Reshape the datasets such that each example is now a vector of size (num_px * num_px * 3, 1) “Standardize” the data 3 - General Architecture of the learning algorithmIt’s time to design a simple algorithm to distinguish cat images from non-cat images. You will build a Logistic Regression, using a Neural Network mindset. The following Figure explains why Logistic Regression is actually a very simple Neural Network! Mathematical expression of the algorithm: For one example $x^{(i)}$:$$z^{(i)} = w^T x^{(i)} + b \tag{1}$$$$\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\tag{2}$$$$ \mathcal{L}(a^{(i)}, y^{(i)}) = - y^{(i)} \log(a^{(i)}) - (1-y^{(i)} ) \log(1-a^{(i)})\tag{3}$$ The cost is then computed by summing over all training examples:$$ J = \frac{1}{m} \sum_{i=1}^m \mathcal{L}(a^{(i)}, y^{(i)})\tag{6}$$ Key steps:In this exercise, you will carry out the following steps: - Initialize the parameters of the model - Learn the parameters for the model by minimizing the cost - Use the learned parameters to make predictions (on the test set) - Analyse the results and conclude 4 - Building the parts of our algorithmThe main steps for building a Neural Network are: Define the model structure (such as number of input features) Initialize the model’s parameters Loop: Calculate current loss (forward propagation) Calculate current gradient (backward propagation) Update parameters (gradient descent) You often build 1-3 separately and integrate them into one function we call model(). 4.1 - Helper functionsExercise: Using your code from “Python Basics”, implement sigmoid(). As you’ve seen in the figure above, you need to compute $sigmoid( w^T x + b) = \frac{1}{1 + e^{-(w^T x + b)}}$ to make predictions. Use np.exp(). 123456789101112131415161718# GRADED FUNCTION: sigmoiddef sigmoid(z): """ Compute the sigmoid of z Arguments: z -- A scalar or numpy array of any size. Return: s -- sigmoid(z) """ ### START CODE HERE ### (≈ 1 line of code) s = 1 / (1 + np.exp(-z)) ### END CODE HERE ### return s 1print ("sigmoid([0, 2]) = " + str(sigmoid(np.array([0,2])))) sigmoid([0, 2]) = [0.5 0.88079708] ​ Expected Output: sigmoid([0, 2]) [ 0.5 0.88079708] 4.2 - Initializing parametersExercise: Implement parameter initialization in the cell below. You have to initialize w as a vector of zeros. If you don’t know what numpy function to use, look up np.zeros() in the Numpy library’s documentation. 12345678910111213141516171819202122# GRADED FUNCTION: initialize_with_zerosdef initialize_with_zeros(dim): """ This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0. Argument: dim -- size of the w vector we want (or number of parameters in this case) Returns: w -- initialized vector of shape (dim, 1) b -- initialized scalar (corresponds to the bias) """ ### START CODE HERE ### (≈ 1 line of code) w = np.zeros((dim, 1)) b = 0 ### END CODE HERE ### assert(w.shape == (dim, 1)) assert(isinstance(b, float) or isinstance(b, int)) return w, b 12345678910dim = 2w, b = initialize_with_zeros(dim)print ("w = " + str(w))print ("b = " + str(b))"""(2, 1)w = [[0.] [0.]]b = 0""" Expected Output: w [[ 0.] [ 0.]] b 0 For image inputs, w will be of shape (num_px $\times$ num_px $\times$ 3, 1). 4.3 - Forward and Backward propagationNow that your parameters are initialized, you can do the “forward” and “backward” propagation steps for learning the parameters. Exercise: Implement a function propagate() that computes the cost function and its gradient. Hints: Forward Propagation: You get X You compute $A = \sigma(w^T X + b) = (a^{(0)}, a^{(1)}, …, a^{(m-1)}, a^{(m)})$ You calculate the cost function: $J = -\frac{1}{m}\sum_{i=1}^{m}y^{(i)}\log(a^{(i)})+(1-y^{(i)})\log(1-a^{(i)})$ Here are the two formulas you will be using: $$ \frac{\partial J}{\partial w} = \frac{1}{m}X(A-Y)^T\tag{7}$$$$ \frac{\partial J}{\partial b} = \frac{1}{m} \sum_{i=1}^m (a^{(i)}-y^{(i)})\tag{8}$$ 123456789101112131415161718192021222324252627282930313233343536373839404142434445# GRADED FUNCTION: propagatedef propagate(w, b, X, Y): """ Implement the cost function and its gradient for the propagation explained above Arguments: w -- weights, a numpy array of size (num_px * num_px * 3, 1) b -- bias, a scalar X -- data of size (num_px * num_px * 3, number of examples) Y -- true "label" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples) Return: cost -- negative log-likelihood cost for logistic regression dw -- gradient of the loss with respect to w, thus same shape as w db -- gradient of the loss with respect to b, thus same shape as b Tips: - Write your code step by step for the propagation. np.log(), np.dot() """ m = X.shape[1] # FORWARD PROPAGATION (FROM X TO COST) ### START CODE HERE ### (≈ 2 lines of code) A = sigmoid(w.T@X + b) # compute activation cost = (-Y*np.log(A) + (Y-1)*np.log(1-A)).sum() / m # compute cost ### END CODE HERE ### # BACKWARD PROPAGATION (TO FIND GRAD) ### START CODE HERE ### (≈ 2 lines of code) dw = (X@(A-Y).T) / m db = (A - Y).mean() ### END CODE HERE ### assert(dw.shape == w.shape) assert(db.dtype == float) cost = np.squeeze(cost) assert(cost.shape == ()), cost.shape grads = &#123;"dw": dw, "db": db&#125; return grads, cost 12345w, b, X, Y = np.array([[1],[2]]), 2, np.array([[1,2],[3,4]]), np.array([[1,0]])grads, cost = propagate(w, b, X, Y)print ("dw = " + str(grads["dw"]))print ("db = " + str(grads["db"]))print ("cost = " + str(cost)) dw = [[0.99993216] [1.99980262]] db = 0.49993523062470574 cost = 6.000064773192205 Expected Output: dw [[ 0.99993216] [ 1.99980262]] db 0.499935230625 cost 6.000064773192205 d) Optimization You have initialized your parameters. You are also able to compute a cost function and its gradient. Now, you want to update the parameters using gradient descent. Exercise: Write down the optimization function. The goal is to learn $w$ and $b$ by minimizing the cost function $J$. For a parameter $\theta$, the update rule is $ \theta = \theta - \alpha \text{ } d\theta$, where $\alpha$ is the learning rate. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# GRADED FUNCTION: optimizedef optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False): """ This function optimizes w and b by running a gradient descent algorithm Arguments: w -- weights, a numpy array of size (num_px * num_px * 3, 1) b -- bias, a scalar X -- data of shape (num_px * num_px * 3, number of examples) Y -- true "label" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples) num_iterations -- number of iterations of the optimization loop learning_rate -- learning rate of the gradient descent update rule print_cost -- True to print the loss every 100 steps Returns: params -- dictionary containing the weights w and bias b grads -- dictionary containing the gradients of the weights and bias with respect to the cost function costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve. Tips: You basically need to write down two steps and iterate through them: 1) Calculate the cost and the gradient for the current parameters. Use propagate(). 2) Update the parameters using gradient descent rule for w and b. """ costs = [] for i in range(num_iterations): # Cost and gradient calculation (≈ 1-4 lines of code) ### START CODE HERE ### grads, cost = propagate(w, b, X, Y) ### END CODE HERE ### # Retrieve derivatives from grads dw = grads["dw"] db = grads["db"] # update rule (≈ 2 lines of code) ### START CODE HERE ### w = w - learning_rate * dw b = b - learning_rate * db ### END CODE HERE ### # Record the costs，每过100个样本，记录代价 if i % 100 == 0: costs.append(cost) # Print the cost every 100 training examples if print_cost and i % 100 == 0: print ("Cost after iteration %i: %f" %(i, cost)) params = &#123;"w": w, "b": b&#125; grads = &#123;"dw": dw, "db": db&#125; return params, grads, costs 123456params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)print ("w = " + str(params["w"]))print ("b = " + str(params["b"]))print ("dw = " + str(grads["dw"]))print ("db = " + str(grads["db"])) w = [[0.1124579 ] [0.23106775]] b = 1.5593049248448891 dw = [[0.90158428] [1.76250842]] db = 0.4304620716786828 Expected Output: w [[ 0.1124579 ] [ 0.23106775]] b 1.55930492484 dw [[ 0.90158428] [ 1.76250842]] db 0.430462071679 Exercise: The previous function will output the learned w and b. We are able to use w and b to predict the labels for a dataset X. Implement the predict() function. There is two steps to computing predictions: Calculate $\hat{Y} = A = \sigma(w^T X + b)$ Convert the entries of a into 0 (if activation &lt;= 0.5) or 1 (if activation &gt; 0.5), stores the predictions in a vector Y_prediction. If you wish, you can use an if/else statement in a for loop (though there is also a way to vectorize this). 12345678910111213141516171819202122232425262728293031323334353637# GRADED FUNCTION: predictdef predict(w, b, X): ''' Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b) Arguments: w -- weights, a numpy array of size (num_px * num_px * 3, 1) b -- bias, a scalar X -- data of size (num_px * num_px * 3, number of examples) Returns: Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X ''' m = X.shape[1] Y_prediction = np.zeros((1,m)) w = w.reshape(X.shape[0], 1) # Compute vector "A" predicting the probabilities of a cat being present in the picture ### START CODE HERE ### (≈ 1 line of code) A = sigmoid(w.T @ X + b) ### END CODE HERE ### for i in range(A.shape[1]): # Convert probabilities A[0,i] to actual predictions p[0,i] ### START CODE HERE ### (≈ 4 lines of code) if A[0, i] &lt; 0.5: Y_prediction[0, i] = 0 else: Y_prediction[0, i] = 1 ### END CODE HERE ### assert(Y_prediction.shape == (1, m)) return Y_prediction 1print ("predictions = " + str(predict(w, b, X))) predictions = [[1. 1.]] ​ Expected Output: predictions [[ 1. 1.]] What to remember:You’ve implemented several functions that: Initialize (w,b) Optimize the loss iteratively to learn parameters (w,b): computing the cost and its gradient updating the parameters using gradient descent Use the learned (w,b) to predict the labels for a given set of examples 5 - Merge all functions into a modelYou will now see how the overall model is structured by putting together all the building blocks (functions implemented in the previous parts) together, in the right order. Exercise: Implement the model function. Use the following notation: - Y_prediction for your predictions on the test set - Y_prediction_train for your predictions on the train set - w, costs, grads for the outputs of optimize() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# GRADED FUNCTION: modeldef model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False): """ Builds the logistic regression model by calling the function you've implemented previously Arguments: X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train) Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train) X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test) Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test) num_iterations -- hyperparameter representing the number of iterations to optimize the parameters learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize() print_cost -- Set to true to print the cost every 100 iterations Returns: d -- dictionary containing information about the model. """ ### START CODE HERE ### # initialize parameters with zeros (≈ 1 line of code) w, b = initialize_with_zeros(X_train.shape[0]) # Gradient descent (≈ 1 line of code) parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost) # Retrieve parameters w and b from dictionary "parameters" w = parameters['w'] b = parameters['b'] # Predict test/train set examples (≈ 2 lines of code) Y_prediction_test = predict(w, b, X_test) Y_prediction_train = predict(w, b, X_train) ### END CODE HERE ### # Print train/test Errors print("train accuracy: &#123;&#125; %".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100)) print("test accuracy: &#123;&#125; %".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100)) d = &#123;"costs": costs, "Y_prediction_test": Y_prediction_test, "Y_prediction_train" : Y_prediction_train, "w" : w, "b" : b, "learning_rate" : learning_rate, "num_iterations": num_iterations&#125; return d Run the following cell to train your model. 1d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True) Expected Output: ​ Train Accuracy 99.04306220095694 % Test Accuracy 70.0 % Comment: Training accuracy is close to 100%. This is a good sanity check: your model is working and has high enough capacity to fit the training data. Test error is 68%. It is actually not bad for this simple model, given the small dataset we used and that logistic regression is a linear classifier. But no worries, you’ll build an even better classifier next week! Also, you see that the model is clearly overfitting the training data. Later in this specialization you will learn how to reduce overfitting, for example by using regularization. Using the code below (and changing the index variable) you can look at predictions on pictures of the test set. 这里的classes的类型是dtype=’|S7’ ，取值的时候，需要用int强转一下，否则报错。 1234# Example of a picture that was wrongly classified.index = 23plt.imshow(test_set_x[:,index].reshape((num_px, num_px, 3)))print ("y = " + str(test_set_y[0,index]) + ", you predicted that it is a \"" + classes[int(d["Y_prediction_test"][0,index])].decode("utf-8") + "\" picture.") y = 1, you predicted that it is a &quot;cat&quot; picture. ​ Let’s also plot the cost function and the gradients. 1234567# Plot learning curve (with costs)costs = np.squeeze(d['costs'])plt.plot(costs)plt.ylabel('cost')plt.xlabel('iterations (per hundreds)')plt.title("Learning rate =" + str(d["learning_rate"]))plt.show() Interpretation:You can see the cost decreasing. It shows that the parameters are being learned. However, you see that you could train the model even more on the training set. Try to increase the number of iterations in the cell above and rerun the cells. You might see that the training set accuracy goes up, but the test set accuracy goes down. This is called overfitting. 6 - Further analysis (optional/ungraded exercise)Congratulations on building your first image classification model. Let’s analyze it further, and examine possible choices for the learning rate $\alpha$. Choice of learning rateReminder:In order for Gradient Descent to work you must choose the learning rate wisely. The learning rate $\alpha$ determines how rapidly we update the parameters. If the learning rate is too large we may “overshoot” the optimal value. Similarly, if it is too small we will need too many iterations to converge to the best values. That’s why it is crucial to use a well-tuned learning rate. Let’s compare the learning curve of our model with several choices of learning rates. Run the cell below. This should take about 1 minute. Feel free also to try different values than the three we have initialized the learning_rates variable to contain, and see what happens. 1234567891011121314151617learning_rates = [0.01, 0.001, 0.0001]models = &#123;&#125;for i in learning_rates: print ("learning rate is: " + str(i)) models[str(i)] = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 1500, learning_rate = i, print_cost = False) print ('\n' + "-------------------------------------------------------" + '\n')for i in learning_rates: plt.plot(np.squeeze(models[str(i)]["costs"]), label= str(models[str(i)]["learning_rate"]))plt.ylabel('cost')plt.xlabel('iterations')legend = plt.legend(loc='upper center', shadow=True)frame = legend.get_frame()frame.set_facecolor('0.90')plt.show() learning rate is: 0.01 train accuracy: 99.52153110047847 % test accuracy: 68.0 % ------------------------------------------------------- learning rate is: 0.001 train accuracy: 88.99521531100478 % test accuracy: 64.0 % ------------------------------------------------------- learning rate is: 0.0001 train accuracy: 68.42105263157895 % test accuracy: 36.0 % ------------------------------------------------------- ​ Interpretation: Different learning rates give different costs and thus different predictions results. If the learning rate is too large (0.01), the cost may oscillate up and down. It may even diverge (though in this example, using 0.01 still eventually ends up at a good value for the cost). A lower cost doesn’t mean a better model. You have to check if there is possibly overfitting. It happens when the training accuracy is a lot higher than the test accuracy. In deep learning, we usually recommend that you: Choose the learning rate that better minimizes the cost function. If your model overfits, use other techniques to reduce overfitting. (We’ll talk about this in later videos.) 7 - Test with your own image (optional/ungraded exercise)Congratulations on finishing this assignment. You can use your own image and see the output of your model. To do that: 1. Click on &quot;File&quot; in the upper bar of this notebook, then click &quot;Open&quot; to go on your Coursera Hub. 2. Add your image to this Jupyter Notebook&apos;s directory, in the &quot;images&quot; folder 3. Change your image&apos;s name in the following code 4. Run the code and check if the algorithm is right (1 = cat, 0 = non-cat)! 123456789101112## START CODE HERE ## (PUT YOUR IMAGE NAME) my_image = "cat_in_iran.jpg" # change this to the name of your image file ## END CODE HERE ### We preprocess the image to fit your algorithm.fname = "images/" + my_imageimage = np.array(ndimage.imread(fname, flatten=False))my_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((1, num_px*num_px*3)).Tmy_predicted_image = predict(d["w"], d["b"], my_image)plt.imshow(image)print("y = " + str(np.squeeze(my_predicted_image)) + ", your algorithm predicts a \"" + classes[int(np.squeeze(my_predicted_image)),].decode("utf-8") + "\" picture.") D:\Anaconda3\envs\Tensorflow\lib\site-packages\ipykernel_launcher.py:7: DeprecationWarning: `imread` is deprecated! `imread` is deprecated in SciPy 1.0.0. Use ``matplotlib.pyplot.imread`` instead. import sys D:\Anaconda3\envs\Tensorflow\lib\site-packages\ipykernel_launcher.py:8: DeprecationWarning: `imresize` is deprecated! `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0. Use ``skimage.transform.resize`` instead. ​ y = 1.0, your algorithm predicts a &quot;cat&quot; picture. ​ What to remember from this assignment: Preprocessing the dataset is important. You implemented each function separately: initialize(), propagate(), optimize(). Then you built a model(). Tuning the learning rate (which is an example of a “hyperparameter”) can make a big difference to the algorithm. You will see more examples of this later in this course! Finally, if you’d like, we invite you to try different things on this Notebook. Make sure you submit before trying anything. Once you submit, things you can play with include: - Play with the learning rate and the number of iterations - Try different initialization methods and compare the results - Test other preprocessings (center the data, or divide each row by its standard deviation) Bibliography: http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/ https://stats.stackexchange.com/questions/211436/why-do-we-normalize-images-by-subtracting-the-datasets-image-mean-and-not-the-c]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达机器学习作业Python实现(八)：异常检测和推荐系统]]></title>
    <url>%2F2018%2F06%2F01%2F180601-%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E5%92%8C%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[1 Anomaly detection这部分，您将实现一个异常检测算法来检测服务器计算机中的异常行为。他的特征是测量每个服务器的响应速度(mb/s)和延迟(ms)。当你的服务器运行时，你收集到了m=307的样本，是无标签的。你相信其中绝大多数样本是正常的，但还是有一小部分的样本是异常的。 我们将使用高斯分布模型来检测数据集中的异常样本。 12345% matplotlib inlineimport pandas as pdimport numpy as npfrom scipy.io import loadmatimport matplotlib.pyplot as plt 1234567mat = loadmat('data/ex8data1.mat')print(mat.keys())# dict_keys(['__header__', '__version__', '__globals__', 'X', 'Xval', 'yval'])X = mat['X']Xval, yval = mat['Xval'], mat['yval']X.shape, Xval.shape, yval.shape# ((307, 2), (307, 2), (307, 1)) 123456def plot_data(): plt.figure(figsize=(8,5)) plt.plot(X[:,0], X[:,1], 'bx') # plt.scatter(Xval[:,0], Xval[:,1], c=yval.flatten(), marker='x', cmap='rainbow') plot_data() 1.1 Gaussian distribution要执行异常检测，首先需要将模型拟合数据的分布。 给定训练集${x^{(1)}, …, x^{(m)}}$, 我们想要对每个特征$x_i$ 做高斯分布估计。对于每个特征，$i = 1…n$，我们需要找到参数 $u_i, \delta^2_i$ 来拟合数据。 12345678910111213141516171819202122232425262728293031323334353637def gaussian(X, mu, sigma2): ''' mu, sigma2参数已经决定了一个高斯分布模型 因为原始模型就是多元高斯模型在sigma2上是对角矩阵而已，所以如下： If Sigma2 is a matrix, it is treated as the covariance matrix. If Sigma2 is a vector, it is treated as the sigma^2 values of the variances in each dimension (a diagonal covariance matrix) output: 一个(m, )维向量，包含每个样本的概率值。 '''# 如果想用矩阵相乘求解exp()中的项，一定要注意维度的变换。# 事实上我们只需要取对角线上的元素即可。（类似于方差而不是想要协方差）# 最后得到一个（m，）的向量，包含每个样本的概率，而不是想要一个（m,m）的矩阵# 注意这里，当矩阵过大时，numpy矩阵相乘会出现内存错误。例如9万维的矩阵。所以画图时不能生成太多数据~！# n = len(mu) # if np.ndim(sigma2) == 1:# sigma2 = np.diag(sigma2)# X = X - mu# p1 = np.power(2 * np.pi, -n/2)*np.sqrt(np.linalg.det(sigma2))# e = np.diag(X@np.linalg.inv(sigma2)@X.T) # 取对角元素，类似与方差，而不要协方差# p2 = np.exp(-.5*e) # return p1 * p2# 下面是不利用矩阵的解法，相当于把每行数据输入进去，不会出现内存错误。 m, n = X.shape if np.ndim(sigma2) == 1: sigma2 = np.diag(sigma2) norm = 1./(np.power((2*np.pi), n/2)*np.sqrt(np.linalg.det(sigma2))) exp = np.zeros((m,1)) for row in range(m): xrow = X[row] exp[row] = np.exp(-0.5*((xrow-mu).T).dot(np.linalg.inv(sigma2)).dot(xrow-mu)) return norm*exp 1.2 Estimating parameters for a Gaussian参数估计： 1234567891011121314def getGaussianParams(X, useMultivariate): """ The input X is the dataset with each n-dimensional data point in one row The output is an n-dimensional vector mu, the mean of the data set the variances sigma^2, an n x 1 vector 或者是(n,n)矩阵，if你使用了多元高斯函数 作业这里求样本方差除的是 m 而不是 m - 1，实际上效果差不了多少。 """ mu = X.mean(axis=0) if useMultivariate: sigma2 = ((X-mu).T @ (X-mu)) / len(X) else: sigma2 = X.var(axis=0, ddof=0) # 样本方差 return mu, sigma2 12345678910111213141516171819def plotContours(mu, sigma2): """ 画出高斯概率分布的图，在三维中是一个上凸的曲面。投影到平面上则是一圈圈的等高线。 """ delta = .3 # 注意delta不能太小！！！否则会生成太多的数据，导致矩阵相乘会出现内存错误。 x = np.arange(0,30,delta) y = np.arange(0,30,delta) # 这部分要转化为X形式的坐标矩阵，也就是一列是横坐标，一列是纵坐标， # 然后才能传入gaussian中求解得到每个点的概率值 xx, yy = np.meshgrid(x, y) points = np.c_[xx.ravel(), yy.ravel()] # 按列合并，一列横坐标，一列纵坐标 z = gaussian(points, mu, sigma2) z = z.reshape(xx.shape) # 这步骤不能忘 cont_levels = [10**h for h in range(-20,0,3)] plt.contour(xx, yy, z, cont_levels) # 这个levels是作业里面给的参考,或者通过求解的概率推出来。 plt.title('Gaussian Contours',fontsize=16) 12345678910# First contours without using multivariate gaussian:plot_data()useMV = FalseplotContours(*getGaussianParams(X, useMV))# Then contours with multivariate gaussian:plot_data()useMV = True# *表示解元组plotContours(*getGaussianParams(X, useMV)) 从上面的图可以看到，一元高斯模型仅在横向和纵向上有变化，而多元高斯模型在斜轴上也有相关变化，对应着特征间的相关关系。而一元高斯模型就是多元高斯模型中协方差矩阵为对角矩阵的结果，即协方差都为0，不考虑协方差，只考虑方差，故一元高斯模型不会有斜轴上的变化。 从上面的图我们可以清晰的看到，哪些样本的概率高，哪些样本的概率低，概率低的样本很大程度上就是异常值。 1.3 Selecting the threshold, ε确定哪些例子是异常的一种方法是通过一组交叉验证集，选择一个好的阈值 ε 。 在这部分的练习中,您将实现一个算法使用交叉验证集的F1分数来选择合理的阈值 ε 。 tp means true positives：是异常值，并且我们的模型预测成异常值了，即真的异常值。 fp means false positives：是正常值，但模型把它预测成异常值，即假的异常值。 fn means false negatives：是异常值，但是模型把它预测成正常值，即假的正常值。 precision 表示你预测为positive的样本中有多少是真的positive的样本。recall 表示实际有多少positive的样本，而你成功预测出多少positive的样本。 123456789101112131415161718192021def selectThreshold(yval, pval): def computeF1(yval, pval): m = len(yval) tp = float(len([i for i in range(m) if pval[i] and yval[i]])) fp = float(len([i for i in range(m) if pval[i] and not yval[i]])) fn = float(len([i for i in range(m) if not pval[i] and yval[i]])) prec = tp/(tp+fp) if (tp+fp) else 0 rec = tp/(tp+fn) if (tp+fn) else 0 F1 = 2*prec*rec/(prec+rec) if (prec+rec) else 0 return F1 epsilons = np.linspace(min(pval), max(pval), 1000) bestF1, bestEpsilon = 0, 0 for e in epsilons: pval_ = pval &lt; e thisF1 = computeF1(yval, pval_) if thisF1 &gt; bestF1: bestF1 = thisF1 bestEpsilon = e return bestF1, bestEpsilon you should see a value epsilon of about 8.99e-05 you should see a Best F1 value of 0.875000 1234mu, sigma2 = getGaussianParams(X, useMultivariate=False)pval = gaussian(Xval, mu, sigma2)bestF1, bestEpsilon = selectThreshold(yval, pval) # (0.8750000000000001, 8.999852631901397e-05) 123y = gaussian(X, mu, sigma2) # X的概率xx = np.array([X[i] for i in range(len(y)) if y[i] &lt; bestEpsilon])xx # 离群点 123plot_data()plotContours(mu, sigma2)plt.scatter(xx[:,0], xx[:,1], s=80, facecolors='none', edgecolors='r') 1.4 High dimensional dataset1234mat = loadmat( 'data/ex8data2.mat' )X2 = mat['X']Xval2, yval2 = mat['Xval'], mat['yval']X2.shape # (1000, 11) 12345678910mu, sigma2 = getGaussianParams(X2, useMultivariate=False)ypred = gaussian(X2, mu, sigma2)yval2pred = gaussian(Xval2, mu, sigma2)# You should see a value epsilon of about 1.38e-18, and 117 anomalies found.bestF1, bestEps = selectThreshold(yval2, yval2pred)anoms = [X2[i] for i in range(X2.shape[0]) if ypred[i] &lt; bestEps]bestEps, len(anoms)# (1.378607498200024e-18, 117) 2 Recommender Systems实际上呢，这里使用的就是改良后的SVD矩阵分解算法。矩阵分解在协同过滤推荐算法中的应用 这一部分，将实现协同过滤学习算法，并将其应用于电影评分数据集。这个数据集由1到5的等级组成。数据集有$n_u$ = 943个用户，$n_m$ = 1682部电影。 2.1 Movie ratings dataset矩阵Y(nm, nu)是不同电影的不同用户的评分，行数为电影数目，列数为用户数目。 矩阵R是二进制指示矩阵，R(i, j)=1 表示用户j 对电影i 有评分，R(i, j)=0 表示用户j对电影i没有评分。 协同过滤的目标是预测用户还没有评分的电影的评分，也就是R(i, j) = 0的项。这将允许我们向用户推荐预测收视率最高的电影。 X第i行代表第i个电影的特征向量$x^{(i)}$，theta矩阵的第j列代表第j用户一个参数向量$\theta_{(j)}$。$x^{(i)}$ 和 $\theta^{(j)}$ 都是n维向量。 这个练习，我们取n=100(这里实际上已经做了降维分解)，所以，X is a ($n_m$, 100) matrix and $\theta$ is a ($n_u$, 100) matrix. 1234567mat = loadmat('data/ex8_movies.mat')print(mat.keys())Y, R = mat['Y'], mat['R']nm, nu = Y.shape # Y中0代表用户没有评分nf = 100Y.shape, R.shape# ((1682, 943), (1682, 943)) 先来求第一个电影的评分的平均值，注意有些人是没有评分这电影的。 1Y[0].sum() / R[0].sum() # 分子代表第一个电影的总分数，分母代表这部电影有多少评分数据 123456# "Visualize the ratings matrix"fig = plt.figure(figsize=(8,8*(1682./943.)))plt.imshow(Y, cmap='rainbow')plt.colorbar()plt.ylabel('Movies (%d)'%nm,fontsize=20)plt.xlabel('Users (%d)'%nu,fontsize=20) 2.2 Collaborative filtering learning algorithm这部分实现协同过滤算法，首先实现代价函数。 这里我们考虑对每一个参数$x^{(1…n_m)}\;and\;\theta^{(1…n_u)}$，都是一个n维的向量，这个n我们选取100。用户j对电影i的评分表示为$y^{(i,j)}=(\theta^{(\;j\;)})^Tx^{(i)}$，给定一个评分数据集，我们想要学习出 $x^{(1)},…,x^{(n_m)}\;and\;\theta^{(1)},…,\theta^{(n_u)}$，使代价函数最小。 也就是X矩阵，和θ矩阵。 为了使用高级优化算法，我们要将X和θ的参数量结合成一维的数组传入，在函数中再分解。 123456789101112mat = loadmat('data/ex8_movieParams.mat')X = mat['X']Theta = mat['Theta']nu = int(mat['num_users'])nm = int(mat['num_movies'])nf = int(mat['num_features'])# For now, reduce the data set size so that this runs fasternu = 4; nm = 5; nf = 3X = X[:nm,:nf]Theta = Theta[:nu,:nf]Y = Y[:nm,:nu]R = R[:nm,:nu] 1X.shape, Theta.shape ((5, 3), (4, 3)) 2.2.1 Collaborative filtering cost function协同过滤的参数都不需要加偏置项了，故都可以正则化。 123def serialize(X, Theta): '''展开参数''' return np.r_[X.flatten(),Theta.flatten()] 123def deserialize(seq, nm, nu, nf): '''提取参数''' return seq[:nm*nf].reshape(nm, nf), seq[nm*nf:].reshape(nu, nf) 12345678910111213141516171819def cofiCostFunc(params, Y, R, nm, nu, nf, l=0): """ params : 拉成一维之后的参数向量(X, Theta) Y : 评分矩阵 (nm, nu) R ：0-1矩阵，表示用户对某一电影有无评分 nu : 用户数量 nm : 电影数量 nf : 自定义的特征的维度 l : lambda for regularization """ X, Theta = deserialize(params, nm, nu, nf) # (X@Theta)*R含义如下： 因为X@Theta是我们用自定义参数算的评分，但是有些电影本来是没有人 # 评分的，存储在R中，0-1表示。将这两个相乘，得到的值就是我们要的已经被评分过的电影的预测分数。 error = 0.5*np.square((X@Theta.T - Y)*R).sum() reg1 = .5*l*np.square(Theta).sum() reg2 = .5*l*np.square(X).sum() return error + reg1 +reg2 12cofiCostFunc(serialize(X,Theta),Y,R,nm,nu,nf),cofiCostFunc(serialize(X,Theta),Y,R,nm,nu,nf,1.5)# (22.224603725685675, 31.34405624427422) 2.2.2 Collaborative filtering gradient 12345678910def cofiGradient(params, Y, R, nm, nu, nf, l=0): """ 计算X和Theta的梯度，并序列化输出。 """ X, Theta = deserialize(params, nm, nu, nf) X_grad = ((X@Theta.T-Y)*R)@Theta + l*X Theta_grad = ((X@Theta.T-Y)*R).T@X + l*Theta return serialize(X_grad, Theta_grad) 12345678910111213141516171819202122232425def checkGradient(params, Y, myR, nm, nu, nf, l = 0.): """ Let's check my gradient computation real quick """ print('Numerical Gradient \t cofiGrad \t\t Difference') # 分析出来的梯度 grad = cofiGradient(params,Y,myR,nm,nu,nf,l) # 用 微小的e 来计算数值梯度。 e = 0.0001 nparams = len(params) e_vec = np.zeros(nparams) # Choose 10 random elements of param vector and compute the numerical gradient # 每次只能改变e_vec中的一个值，并在计算完数值梯度后要还原。 for i in range(10): idx = np.random.randint(0,nparams) e_vec[idx] = e loss1 = cofiCostFunc(params-e_vec,Y,myR,nm,nu,nf,l) loss2 = cofiCostFunc(params+e_vec,Y,myR,nm,nu,nf,l) numgrad = (loss2 - loss1) / (2*e) e_vec[idx] = 0 diff = np.linalg.norm(numgrad - grad[idx]) / np.linalg.norm(numgrad + grad[idx]) print('%0.15f \t %0.15f \t %0.15f' %(numgrad, grad[idx], diff)) 1234print("Checking gradient with lambda = 0...")checkGradient(serialize(X,Theta), Y, R, nm, nu, nf)print("\nChecking gradient with lambda = 1.5...")checkGradient(serialize(X,Theta), Y, R, nm, nu, nf, l=1.5) 2.3 Learning movie recommendations在我们训练协同过滤模型之前，我们先要获取所有电影的名称以及 添加与我们刚才观察到的新用户对应的评分。 12345movies = [] # 包含所有电影的列表with open('data/movie_ids.txt','r', encoding='utf-8') as f: for line in f:# movies.append(' '.join(line.strip().split(' ')[1:])) movies.append(' '.join(line.strip().split(' ')[1:])) 1234567891011121314151617my_ratings = np.zeros((1682,1))my_ratings[0] = 4my_ratings[97] = 2my_ratings[6] = 3my_ratings[11] = 5my_ratings[53] = 4my_ratings[63] = 5my_ratings[65] = 3my_ratings[68] = 5my_ratings[182] = 4my_ratings[225] = 5my_ratings[354] = 5for i in range(len(my_ratings)): if my_ratings[i] &gt; 0: print(my_ratings[i], movies[i]) 导入Y矩阵以及R矩阵 123mat = loadmat('data/ex8_movies.mat')Y, R = mat['Y'], mat['R']Y.shape, R.shape 将我们刚才添加的新用户数据合并到Y 和R 123Y = np.c_[Y, my_ratings] # (1682, 944)R = np.c_[R, my_ratings!=0] # (1682, 944)nm, nu = Y.shape 1nf = 10 # 我们使用10维的特征向量 均值归一化数据，这个可以使一个完全没有评分的的特征最后也会获得非零值。是因为，最后要加回均值。 注意只对有评分的数据求均值，没有评分的数据不包含在内，要用R矩阵判断。 12345678def normalizeRatings(Y, R): """ The mean is only counting movies that were rated """ Ymean = (Y.sum(axis=1) / R.sum(axis=1)).reshape(-1,1)# Ynorm = (Y - Ymean)*R # 这里也要注意不要归一化未评分的数据 Ynorm = (Y - Ymean)*R # 这里也要注意不要归一化未评分的数据 return Ynorm, Ymean 123Ynorm, Ymean = normalizeRatings(Y, R)Ynorm.shape, Ymean.shape# ((1682, 944), (1682, 1)) 生成初始化参数X矩阵，Theta矩阵 1234X = np.random.random((nm, nf))Theta = np.random.random((nu, nf))params = serialize(X, Theta)l = 10 123456789import scipy.optimize as optres = opt.minimize(fun=cofiCostFunc, x0=params, args=(Y, R, nm, nu, nf, l), method='TNC', jac=cofiGradient, options=&#123;'maxiter': 100&#125;)ret = res.x 123# import scipy.optimize as opt# ret = opt.fmin_cg(cofiCostFunc, x0=params, fprime=cofiGradient, # args=(Y, R, nm, nu, nf, l), maxiter=100) 1fit_X, fit_Theta = deserialize(ret, nm, nu, nf) 2.3.1 Recommendations现在我们就可以利用训练好的参数来预测用户的分数。 12# 所有用户的剧场分数矩阵pred_mat = fit_X @ fit_Theta.T 12# 最后一个用户的预测分数， 也就是我们刚才添加的用户pred = pred_mat[:,-1] + Ymean.flatten() 1pred_sorted_idx = np.argsort(pred)[::-1] # 排序并翻转，使之从大到小排列 作业中最后的截图应该是算错了，用的是非归一化的数据Y来训练的。所以我在这里也在这里用的非归一化的数据Y来训练的。事实上应该用归一化之后的数据Ynorm来训练，可自行尝试。 123456789print("Top recommendations for you:")for i in range(10): print('Predicting rating %0.1f for movie %s.' \ %(pred[pred_sorted_idx[i]],movies[pred_sorted_idx[i]]))print("\nOriginal ratings provided:")for i in range(len(my_ratings)): if my_ratings[i] &gt; 0: print('Rated %d for movie %s.'% (my_ratings[i],movies[i])) Top recommendations for you: Predicting rating 8.5 for movie Titanic (1997). Predicting rating 8.4 for movie Star Wars (1977). Predicting rating 8.3 for movie Shawshank Redemption, The (1994). Predicting rating 8.3 for movie Schindler&apos;s List (1993). Predicting rating 8.3 for movie Raiders of the Lost Ark (1981). Predicting rating 8.2 for movie Good Will Hunting (1997). Predicting rating 8.1 for movie Empire Strikes Back, The (1980). Predicting rating 8.1 for movie Wrong Trousers, The (1993). Predicting rating 8.0 for movie Casablanca (1942). Predicting rating 8.0 for movie Usual Suspects, The (1995). Original ratings provided: Rated 4 for movie Toy Story (1995). Rated 3 for movie Twelve Monkeys (1995). Rated 5 for movie Usual Suspects, The (1995). Rated 4 for movie Outbreak (1995). Rated 5 for movie Shawshank Redemption, The (1994). Rated 3 for movie While You Were Sleeping (1995). Rated 5 for movie Forrest Gump (1994). Rated 2 for movie Silence of the Lambs, The (1991). Rated 4 for movie Alien (1979). Rated 5 for movie Die Hard 2 (1990). Rated 5 for movie Sphere (1998).]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达机器学习作业Python实现(七)：K-means和PCA主成分分析]]></title>
    <url>%2F2018%2F05%2F29%2F180529-K-means%E5%92%8CPCA%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[1 K-means Clustering在这个练习中，您将实现K-means算法并将其用于图像压缩。通过减少图像中出现的颜色的数量，只剩下那些在图像中最常见的颜色。 1.1 Implementing K-means1.1.1 Finding closest centroids在K-means算法的分配簇的阶段，算法将每一个训练样本 $x_i$ 分配给最接近的簇中心。 $c^{(i)}$ 表示离样本$x_i$ 最近的簇中心点。$u_j$ 是第j 个簇中心点的位置（值）， 12345%matplotlib inlineimport numpy as npimport pandas as pdimport matplotlib.pyplot as pltfrom scipy.io import loadmat 1234567891011121314def findClosestCentroids(X, centroids): """ output a one-dimensional array idx that holds the index of the closest centroid to every training example. """ idx = [] max_dist = 1000000 # 限制一下最大距离 for i in range(len(X)): minus = X[i] - centroids # here use numpy's broadcasting dist = minus[:,0]**2 + minus[:,1]**2 if dist.min() &lt; max_dist: ci = np.argmin(dist) idx.append(ci) return np.array(idx) 接下来使用作业提供的例子，自定义一个centroids,[3, 3], [6, 2], [8, 5]，算出结果idx[0:3]应该是 [0, 2, 1] 123456mat = loadmat('data/ex7data2.mat')# print(mat.keys())X = mat['X']init_centroids = np.array([[3, 3], [6, 2], [8, 5]])idx = findClosestCentroids(X, init_centroids)print(idx[0:3]) [0 2 1] ​ 1.1.2 Computing centroid means分配好每个点对应的簇中心，接下来要做的是，重新计算每个簇中心，为这个簇里面所有点位置的平均值。 $C_k$ 是我们分配好给簇中心点的样本集。 1234567def computeCentroids(X, idx): centroids = [] for i in range(len(np.unique(idx))): # np.unique() means K u_k = X[idx==i].mean(axis=0) # 求每列的平均值 centroids.append(u_k) return np.array(centroids) 1computeCentroids(X, idx) array([[2.42830111, 3.15792418], [5.81350331, 2.63365645], [7.11938687, 3.6166844 ]]) 1.2 K-means on example dataset1234567891011121314151617181920212223242526272829303132333435363738394041def plotData(X, centroids, idx=None): """ 可视化数据，并自动分开着色。 idx: 最后一次迭代生成的idx向量，存储每个样本分配的簇中心点的值 centroids: 包含每次中心点历史记录 """ colors = ['b','g','gold','darkorange','salmon','olivedrab', 'maroon', 'navy', 'sienna', 'tomato', 'lightgray', 'gainsboro' 'coral', 'aliceblue', 'dimgray', 'mintcream', 'mintcream'] assert len(centroids[0]) &lt;= len(colors), 'colors not enough ' subX = [] # 分号类的样本点 if idx is not None: for i in range(centroids[0].shape[0]): x_i = X[idx == i] subX.append(x_i) else: subX = [X] # 将X转化为一个元素的列表，每个元素为每个簇的样本集，方便下方绘图 # 分别画出每个簇的点，并着不同的颜色 plt.figure(figsize=(8,5)) for i in range(len(subX)): xx = subX[i] plt.scatter(xx[:,0], xx[:,1], c=colors[i], label='Cluster %d'%i) plt.legend() plt.grid(True) plt.xlabel('x1',fontsize=14) plt.ylabel('x2',fontsize=14) plt.title('Plot of X Points',fontsize=16) # 画出簇中心点的移动轨迹 xx, yy = [], [] for centroid in centroids: xx.append(centroid[:,0]) yy.append(centroid[:,1]) plt.plot(xx, yy, 'rx--', markersize=8) plotData(X, [init_centroids]) 123456789101112131415def runKmeans(X, centroids, max_iters): K = len(centroids) centroids_all = [] centroids_all.append(centroids) centroid_i = centroids for i in range(max_iters): idx = findClosestCentroids(X, centroid_i) centroid_i = computeCentroids(X, idx) centroids_all.append(centroid_i) return idx, centroids_all idx, centroids_all = runKmeans(X, init_centroids, 20)plotData(X, centroids_all, idx) 1.3 Random initialization在实践中，对簇中心点进行初始化的一个好的策略就是从训练集中选择随机的例子。 1234567def initCentroids(X, K): """随机初始化""" m, n = X.shape idx = np.random.choice(m, K) centroids = X[idx] return centroids 进行三次随机初始化，看下各自的效果。会发现第三次的效果并不理想，这是正常的，落入了局部最优。 1234for i in range(3): centroids = initCentroids(X, 3) idx, centroids_all = runKmeans(X, centroids, 10) plotData(X, centroids_all, idx) 上面运行了三次随机初始化，可以看到不同的随机化，效果是不一样的。 1.4 Image compression with K-means这部分你将用Kmeans来进行图片压缩。在一个简单的24位颜色表示图像。每个像素被表示为三个8位无符号整数(从0到255)，指定了红、绿和蓝色的强度值。这种编码通常被称为RGB编码。我们的图像包含数千种颜色，在这一部分的练习中，你将把颜色的数量减少到16种颜色。 这可以有效地压缩照片。具体地说，您只需要存储16个选中颜色的RGB值，而对于图中的每个像素，现在只需要将该颜色的索引存储在该位置(只需要4 bits就能表示16种可能性)。 接下来我们要用K-means算法选16种颜色，用于图片压缩。你将把原始图片的每个像素看作一个数据样本，然后利用K-means算法去找分组最好的16种颜色。 1.4.1 K-means on pixels123456from skimage import ioA = io.imread('data/bird_small.png')print(A.shape)plt.imshow(A);A = A/255. # Divide by 255 so that all values are in the range 0 - 1 (128, 128, 3) ​ 1234567# Reshape the image into an (N,3) matrix where N = number of pixels.# Each row will contain the Red, Green and Blue pixel values# This gives us our dataset matrix X that we will use K-Means on.X = A.reshape(-1, 3)K = 16centroids = initCentroids(X, K)idx, centroids_all = runKmeans(X, centroids, 10) 12345678910img = np.zeros(X.shape)centroids = centroids_all[-1]for i in range(len(centroids)): img[idx == i] = centroids[i] img = img.reshape((128, 128, 3))fig, axes = plt.subplots(1, 2, figsize=(12,6))axes[0].imshow(A)axes[1].imshow(img) &lt;matplotlib.image.AxesImage at 0x2bd54e4ed68&gt; 2 Principal Component Analysis这部分，你将运用PCA来实现降维。您将首先通过一个2D数据集进行实验，以获得关于PCA如何工作的直观感受，然后在一个更大的图像数据集上使用它。 2.1 Example Dataset为了帮助您理解PCA是如何工作的，您将首先从一个二维数据集开始，该数据集有一个大的变化方向和一个较小的变化方向。 在这部分练习中，您将看到使用PCA将数据从2D减少到1D时会发生什么。 1234mat = loadmat('data/ex7data1.mat')X = mat['X']print(X.shape)plt.scatter(X[:,0], X[:,1], facecolors='none', edgecolors='b') (50, 2) ​ 2.2 Implementing PCAPCA由两部分组成： 计算数据的方差矩阵 用SVD计算特征向量$(U_1, U_2, …, U_n)$ 在PCA之前，记得标准化数据。 然后计算方差矩阵，如果你的每条样本数据是以行的形式表示，那么计算公式如下： 接着就可以用SVD计算主成分 U包含了主成分，每一列就是我们数据要映射的向量，S为对角矩阵，为奇异值。 12345def featureNormalize(X): means = X.mean(axis=0) stds = X.std(axis=0, ddof=1) X_norm = (X - means) / stds return X_norm, means, stds 由于我们的协方差矩阵为X.T@X, X中每行为一条数据，我们是想要对列(特征)做压缩。 这里由于是对协方差矩阵做SVD(), 所以得到的入口基其实为 V‘，出口基为V，可以打印出各自的shape来判断。 故我们这里是对 数据集的列 做压缩。 这里讲的很棒 12345def pca(X): sigma = (X.T @ X) / len(X) U, S, V = np.linalg.svd(sigma) return U, S, V 123456789101112131415161718X_norm, means, stds = featureNormalize(X)U, S, V = pca(X_norm)print(U[:,0]) plt.figure(figsize=(7, 5))plt.scatter(X[:,0], X[:,1], facecolors='none', edgecolors='b')plt.plot([means[0], means[0] + 1.5*S[0]*U[0,0]], [means[1], means[1] + 1.5*S[0]*U[0,1]], c='r', linewidth=3, label='First Principal Component')plt.plot([means[0], means[0] + 1.5*S[1]*U[1,0]], [means[1], means[1] + 1.5*S[1]*U[1,1]], c='g', linewidth=3, label='Second Principal Component')plt.grid()# changes limits of x or y axis so that equal increments of x and y have the same length# 不然看着不垂直，不舒服。：）plt.axis("equal") plt.legend() [-0.70710678 -0.70710678] 2.3 Dimensionality Reduction with PCA2.3.1 Projecting the data onto the principal components1234def projectData(X, U, K): Z = X @ U[:,:K] return Z 1234# project the first example onto the first dimension # and you should see a value of about 1.481Z = projectData(X_norm, U, 1)Z[0] array([1.48127391]) 2.3.2 Reconstructing an approximation of the data重建数据 1234def recoverData(Z, U, K): X_rec = Z @ U[:,:K].T return X_rec 1234# you will recover an approximation of the first example and you should see a value of# about [-1.047 -1.047].X_rec = recoverData(Z, U, 1)X_rec[0] array([-1.04741883, -1.04741883]) 2.3.3 Visualizing the projections12345678910111213141516plt.figure(figsize=(7,5))plt.axis("equal") plot = plt.scatter(X_norm[:,0], X_norm[:,1], s=30, facecolors='none', edgecolors='b',label='Original Data Points')plot = plt.scatter(X_rec[:,0], X_rec[:,1], s=30, facecolors='none', edgecolors='r',label='PCA Reduced Data Points')plt.title("Example Dataset: Reduced Dimension Points Shown",fontsize=14)plt.xlabel('x1 [Feature Normalized]',fontsize=14)plt.ylabel('x2 [Feature Normalized]',fontsize=14)plt.grid(True)for x in range(X_norm.shape[0]): plt.plot([X_norm[x,0],X_rec[x,0]],[X_norm[x,1],X_rec[x,1]],'k--') # 输入第一项全是X坐标，第二项都是Y坐标plt.legend() &lt;matplotlib.legend.Legend at 0x2bd54da7b70&gt; 2.4 Face Image Dataset在这部分练习中，您将人脸图像上运行PCA，看看如何在实践中使用它来减少维度。 123mat = loadmat('data/ex7faces.mat')X = mat['X']print(X.shape) (5000, 1024) ​ 123456789def displayData(X, row, col): fig, axs = plt.subplots(row, col, figsize=(8,8)) for r in range(row): for c in range(col): axs[r][c].imshow(X[r*col + c].reshape(32,32).T, cmap = 'Greys_r') axs[r][c].set_xticks([]) axs[r][c].set_yticks([]) displayData(X, 10, 10) 2.4.1 PCA on Faces123X_norm, means, stds = featureNormalize(X)U, S, V = pca(X_norm) 1U.shape, S.shape ((1024, 1024), (1024,)) 1displayData(U[:,:36].T, 6, 6) 2.4.2 Dimensionality Reduction1z = projectData(X_norm, U, K=36) 1X_rec = recoverData(z, U, K=36) 1displayData(X_rec, 10, 10)]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达机器学习作业Python实现(六)：SVM支持向量机]]></title>
    <url>%2F2018%2F05%2F26%2F180526S-SVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[1 Support Vector Machines1.1 Example Dataset 11234567%matplotlib inlineimport numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sbfrom scipy.io import loadmatfrom sklearn import svm 大多数SVM的库会自动帮你添加额外的特征 $x_0$ 已经 $\theta_0$，所以无需手动添加。 12345mat = loadmat('./data/ex6data1.mat')print(mat.keys())# dict_keys(['__header__', '__version__', '__globals__', 'X', 'y'])X = mat['X']y = mat['y'] ​ 1234567def plotData(X, y): plt.figure(figsize=(8,5)) plt.scatter(X[:,0], X[:,1], c=y.flatten(), cmap='rainbow') plt.xlabel('X1') plt.ylabel('X2') plt.legend() plotData(X, y) 123456789def plotBoundary(clf, X): '''plot decision bondary''' x_min, x_max = X[:,0].min()*1.2, X[:,0].max()*1.1 y_min, y_max = X[:,1].min()*1.1,X[:,1].max()*1.1 xx, yy = np.meshgrid(np.linspace(x_min, x_max, 500), np.linspace(y_min, y_max, 500)) Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]) Z = Z.reshape(xx.shape) plt.contour(xx, yy, Z) 12models = [svm.SVC(C, kernel='linear') for C in [1, 100]]clfs = [model.fit(X, y.ravel()) for model in models] 123456title = ['SVM Decision Boundary with C = &#123;&#125; (Example Dataset 1'.format(C) for C in [1, 100]]for model,title in zip(clfs,title): plt.figure(figsize=(8,5)) plotData(X, y) plotBoundary(model, X) plt.title(title) 可以从上图看到，当C比较小时模型对误分类的惩罚增大，比较严格，误分类少，间隔比较狭窄。 当C比较大时模型对误分类的惩罚增大，比较宽松，允许一定的误分类存在，间隔较大。 1.2 SVM with Gaussian Kernels这部分，使用SVM做非线性分类。我们将使用高斯核函数。 为了用SVM找出一个非线性的决策边界，我们首先要实现高斯核函数。我可以把高斯核函数想象成一个相似度函数，用来测量一对样本的距离，$(x^{(i)}, y^{(j)})$ 。 这里我们用sklearn自带的svm中的核函数即可。 1.2.1 Gaussian Kernel1234def gaussKernel(x1, x2, sigma): return np.exp(- ((x1 - x2) ** 2).sum() / (2 * sigma ** 2))gaussKernel(np.array([1, 2, 1]),np.array([0, 4, -1]), 2.) # 0.32465246735834974 1.2.2 Example Dataset 2123mat = loadmat('./data/ex6data2.mat')X2 = mat['X']y2 = mat['y'] 1plotData(X2, y2) ​ 123456sigma = 0.1gamma = np.power(sigma,-2.)/2clf = svm.SVC(C=1, kernel='rbf', gamma=gamma)modle = clf.fit(X2, y2.flatten())plotData(X2, y2)plotBoundary(modle, X2) ​ 1.2.3 Example Dataset 31234mat3 = loadmat('data/ex6data3.mat')X3, y3 = mat3['X'], mat3['y']Xval, yval = mat3['Xval'], mat3['yval']plotData(X3, y3) 123456789101112131415Cvalues = (0.01, 0.03, 0.1, 0.3, 1., 3., 10., 30.)sigmavalues = Cvaluesbest_pair, best_score = (0, 0), 0for C in Cvalues: for sigma in sigmavalues: gamma = np.power(sigma,-2.)/2 model = svm.SVC(C=C,kernel='rbf',gamma=gamma) model.fit(X3, y3.flatten()) this_score = model.score(Xval, yval) if this_score &gt; best_score: best_score = this_score best_pair = (C, sigma)print('best_pair=&#123;&#125;, best_score=&#123;&#125;'.format(best_pair, best_score))# best_pair=(1.0, 0.1), best_score=0.965 1234model = svm.SVC(C=1., kernel='rbf', gamma = np.power(.1, -2.)/2)model.fit(X3, y3.flatten())plotData(X3, y3)plotBoundary(model, X3) 123456789101112131415161718192021222324252627282930313233343536373839404142# 这我的一个练习画图的，和作业无关，给个画图的参考。import numpy as npimport matplotlib.pyplot as pltfrom sklearn import svm# we create 40 separable pointsnp.random.seed(0)X = np.array([[3,3],[4,3],[1,1]])Y = np.array([1,1,-1])# fit the modelclf = svm.SVC(kernel='linear')clf.fit(X, Y)# get the separating hyperplanew = clf.coef_[0]a = -w[0] / w[1]xx = np.linspace(-5, 5)yy = a * xx - (clf.intercept_[0]) / w[1]# plot the parallels to the separating hyperplane that pass through the# support vectorsb = clf.support_vectors_[0]yy_down = a * xx + (b[1] - a * b[0])b = clf.support_vectors_[-1]yy_up = a * xx + (b[1] - a * b[0])# plot the line, the points, and the nearest vectors to the planeplt.figure(figsize=(8,5))plt.plot(xx, yy, 'k-')plt.plot(xx, yy_down, 'k--')plt.plot(xx, yy_up, 'k--')# 圈出支持向量plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=150, facecolors='none', edgecolors='k', linewidths=1.5)plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.rainbow)plt.axis('tight')plt.show()print(clf.decision_function(X)) [ 1. 1.5 -1. ] ​ 2 Spam Classification2.1 Preprocessing Emails这部分用SVM建立一个垃圾邮件分类器。你需要将每个email变成一个n维的特征向量，这个分类器将判断给定一个邮件x是垃圾邮件(y=1)或不是垃圾邮件(y=0)。 take a look at examples from the dataset 123with open('data/emailSample1.txt', 'r') as f: email = f.read() print(email) &gt; Anyone knows how much it costs to host a web portal ? &gt; Well, it depends on how many visitors you&apos;re expecting. This can be anywhere from less than 10 bucks a month to a couple of $100. You should checkout http://www.rackspace.com/ or perhaps Amazon EC2 if youre running something big.. To unsubscribe yourself from this mailing list, send an email to: groupname-unsubscribe@egroups.com ​ 可以看到，邮件内容包含 a URL, an email address(at the end), numbers, and dollar amounts. 很多邮件都会包含这些元素，但是每封邮件的具体内容可能会不一样。因此，处理邮件经常采用的方法是标准化这些数据，把所有URL当作一样，所有数字看作一样。 例如，我们用唯一的一个字符串‘httpaddr’来替换所有的URL，来表示邮件包含URL，而不要求具体的URL内容。这通常会提高垃圾邮件分类器的性能，因为垃圾邮件发送者通常会随机化URL，因此在新的垃圾邮件中再次看到任何特定URL的几率非常小。 我们可以做如下处理： 1. Lower-casing: 把整封邮件转化为小写。 2. Stripping HTML: 移除所有HTML标签，只保留内容。 3. Normalizing URLs: 将所有的URL替换为字符串 “httpaddr”. 4. Normalizing Email Addresses: 所有的地址替换为 “emailaddr” 5. Normalizing Dollars: 所有dollar符号($)替换为“dollar”. 6. Normalizing Numbers: 所有数字替换为“number” 7. Word Stemming(词干提取): 将所有单词还原为词源。例如，“discount”, “discounts”, “discounted” and “discounting”都替换为“discount”。 8. Removal of non-words: 移除所有非文字类型，所有的空格(tabs, newlines, spaces)调整为一个空格. 123456789101112%matplotlib inlineimport numpy as npimport matplotlib.pyplot as pltfrom scipy.io import loadmatfrom sklearn import svmimport re #regular expression for e-mail processing# 这是一个可用的英文分词算法(Porter stemmer)from stemming.porter2 import stem# 这个英文算法似乎更符合作业里面所用的代码，与上面效果差不多import nltk, nltk.stem.porter 123456789def processEmail(email): """做除了Word Stemming和Removal of non-words的所有处理""" email = email.lower() email = re.sub('&lt;[^&lt;&gt;]&gt;', ' ', email) # 匹配&lt;开头，然后所有不是&lt; ,&gt; 的内容，知道&gt;结尾，相当于匹配&lt;...&gt; email = re.sub('(http|https)://[^\s]*', 'httpaddr', email ) # 匹配//后面不是空白字符的内容，遇到空白字符则停止 email = re.sub('[^\s]+@[^\s]+', 'emailaddr', email) email = re.sub('[\$]+', 'dollar', email) email = re.sub('[\d]+', 'number', email) return email 接下来就是提取词干，以及去除非字符内容。 123456789101112131415161718192021222324def email2TokenList(email): """预处理数据，返回一个干净的单词列表""" # I'll use the NLTK stemmer because it more accurately duplicates the # performance of the OCTAVE implementation in the assignment stemmer = nltk.stem.porter.PorterStemmer() email = preProcess(email) # 将邮件分割为单个单词，re.split() 可以设置多种分隔符 tokens = re.split('[ \@\$\/\#\.\-\:\&amp;\*\+\=\[\]\?\!\(\)\&#123;\&#125;\,\'\"\&gt;\_\&lt;\;\%]', email) # 遍历每个分割出来的内容 tokenlist = [] for token in tokens: # 删除任何非字母数字的字符 token = re.sub('[^a-zA-Z0-9]', '', token); # Use the Porter stemmer to 提取词根 stemmed = stemmer.stem(token) # 去除空字符串‘’，里面不含任何字符 if not len(token): continue tokenlist.append(stemmed) return tokenlist 2.1.1 Vocabulary List(词汇表)在对邮件进行预处理之后，我们有一个处理后的单词列表。下一步是选择我们想在分类器中使用哪些词，我们需要去除哪些词。 我们有一个词汇表vocab.txt，里面存储了在实际中经常使用的单词，共1899个。 我们要算出处理后的email中含有多少vocab.txt中的单词，并返回在vocab.txt中的index，这就我们想要的训练单词的索引。 12345def email2VocabIndices(email, vocab): """提取存在单词的索引""" token = email2TokenList(email) index = [i for i in range(len(vocab)) if vocab[i] in token ] return index 2.2 Extracting Features from Emails123456789101112def email2FeatureVector(email): """ 将email转化为词向量，n是vocab的长度。存在单词的相应位置的值置为1，其余为0 """ df = pd.read_table('data/vocab.txt',names=['words']) vocab = df.as_matrix() # return array vector = np.zeros(len(vocab)) # init vector vocab_indices = email2VocabIndices(email, vocab) # 返回含有单词的索引 # 将有单词的索引置为1 for i in vocab_indices: vector[i] = 1 return vector 12vector = email2FeatureVector(email)print('length of vector = &#123;&#125;\nnum of non-zero = &#123;&#125;'.format(len(vector), int(vector.sum()))) length of vector = 1899 num of non-zero = 45 2.3 Training SVM for Spam Classification读取已经训提取好的特征向量以及相应的标签。分训练集和测试集。 1234567# Training setmat1 = loadmat('data/spamTrain.mat')X, y = mat1['X'], mat1['y']# Test setmat2 = scipy.io.loadmat('data/spamTest.mat')Xtest, ytest = mat2['Xtest'], mat2['ytest'] 12clf = svm.SVC(C=0.1, kernel='linear')clf.fit(X, y) 2.4 Top Predictors for Spam123predTrain = clf.score(X, y)predTest = clf.score(Xtest, ytest)predTrain, predTest (0.99825, 0.989)]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达机器学习作业Python实现(五)：偏差和方差]]></title>
    <url>%2F2018%2F05%2F23%2F180523-%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE%2F</url>
    <content type="text"><![CDATA[在本练习中，您将实现正则化的线性回归和多项式回归，并使用它来研究具有不同偏差-方差属性的模型 1 Regularized Linear Regression 正则线性回归在前半部分的练习中，你将实现正则化线性回归，以预测水库中的水位变化，从而预测大坝流出的水量。在下半部分中，您将通过一些调试学习算法的诊断，并检查偏差 v.s. 方差的影响。 1.1 Visualizing the dataset我们将从可视化数据集开始，其中包含水位变化的历史记录，x，以及从大坝流出的水量，y。 这个数据集分为了三个部分： training set 训练集：训练模型 cross validation set 交叉验证集：选择正则化参数 test set 测试集：评估性能，模型训练中不曾用过的样本 12345%matplotlib inlineimport numpy as npimport matplotlib.pyplot as pltfrom scipy.io import loadmatimport scipy.optimize as opt 读取数据 123456789101112131415path = 'ex5data1.mat'data = loadmat(path)#Training setX, y = data['X'], data['y']#Cross validation setXval, yval = data['Xval'], data['yval']#Test setXtest, ytest = data['Xtest'], data['ytest']#Insert a column of 1's to all of the X's, as usualX = np.insert(X ,0,1,axis=1)Xval = np.insert(Xval ,0,1,axis=1)Xtest = np.insert(Xtest,0,1,axis=1)print('X=&#123;&#125;,y=&#123;&#125;'.format(X.shape, y.shape))print('Xval=&#123;&#125;,yval=&#123;&#125;'.format(Xval.shape, yval.shape))print('Xtest=&#123;&#125;,ytest=&#123;&#125;'.format(Xtest.shape, ytest.shape)) X=(12, 2),y=(12, 1) Xval=(21, 2),yval=(21, 1) Xtest=(21, 2),ytest=(21, 1) 123456789def plotData(): """瞧一瞧数据长啥样""" plt.figure(figsize=(8,5)) plt.scatter(X[:,1:], y, c='r', marker='x') plt.xlabel('Change in water level (x)') plt.ylabel('Water flowing out of the dam (y)') plt.grid(True) plotData() 1.2 Regularized linear regression cost function 123456789def costReg(theta, X, y, l): '''do not regularizethe theta0 theta is a 1-d array with shape (n+1,) X is a matrix with shape (m, n+1) y is a matrix with shape (m, 1) ''' cost = ((X @ theta - y.flatten()) ** 2).sum() regterm = l * (theta[1:] @ theta[1:]) return (cost + regterm) / (2 * len(X)) Using theta initialized at [1, 1], and lambda = 1, you should expect to see an output of 303.993192 12theta = np.ones(X.shape[1])print(costReg(theta, X, y, 1)) # 303.9931922202643 1.3 Regularized linear regression gradient 12345678910111213141516def gradientReg(theta, X, y, l): """ theta: 1-d array with shape (2,) X: 2-d array with shape (12, 2) y: 2-d array with shape (12, 1) l: lambda constant grad has same shape as theta (2,) """ grad = (X @ theta - y.flatten()) @ X regterm = l * theta regterm[0] = 0 # #don't regulate bias term return (grad + regterm) / len(X)# Using theta initialized at [1; 1] you should expect to see a # gradient of [-15.303016; 598.250744] (with lambda=1)print(gradientReg(theta, X, y, 1)) 1.4 Fitting linear regression 拟合线性回归12345678def trainLinearReg(X, y, l): theta = np.zeros(X.shape[1]) res = opt.minimize(fun=costReg, x0=theta, args=(X, y ,l), method='TNC', jac=gradientReg) return res.x 123fit_theta = trainLinearReg(X, y, 0)plotData()plt.plot(X[:,1], X @ fit_theta) 这里我们把$\lambda$ = 0，因为我们现在实现的线性回归只有两个参数，这么低的维度，正则化并没有用。 从图中可以看到，拟合最好的这条直线告诉我们这个模型并不适合这个数据。 在下一节中，您将实现一个函数来生成学习曲线，它可以帮助您调试学习算法，即使可视化数据不那么容易。 2 Bias-variance机器学习中一个重要的概念是偏差（bias）和方差（variance）的权衡。高偏差意味着欠拟合，高方差意味着过拟合。 在这部分练习中，您将在学习曲线上绘制训练误差和验证误差，以诊断bias-variance问题。 2.1 Learning curves 学习曲线 训练样本X从1开始逐渐增加，训练出不同的参数向量θ。接着通过交叉验证样本Xval计算验证误差。 使用训练集的子集来训练模型，得到不同的theta。 通过theta计算训练代价和交叉验证代价，切记此时不要使用正则化，将 $\lambda = 0$。 计算交叉验证代价时记得整个交叉验证集来计算，无需分为子集。 12345678910111213141516171819def plot_learning_curve(X, y, Xval, yval, l): """画出学习曲线，即交叉验证误差和训练误差随样本数量的变化的变化""" xx = range(1, len(X) + 1) # at least has one example training_cost, cv_cost = [], [] for i in xx: res = trainLinearReg(X[:i], y[:i], l) training_cost_i = costReg(res, X[:i], y[:i], 0) cv_cost_i = costReg(res, Xval, yval, 0) training_cost.append(training_cost_i) cv_cost.append(cv_cost_i) plt.figure(figsize=(8,5)) plt.plot(xx, training_cost, label='training cost') plt.plot(xx, cv_cost, label='cv cost') plt.legend() plt.xlabel('Number of training examples') plt.ylabel('Error') plt.title('Learning curve for linear regression') plt.grid(True) 1learningCurve(X, y, Xval, yval, 0) 从图中看出来，随着样本数量的增加，训练误差和交叉验证误差都很高，这属于高偏差，欠拟合。 3 Polynomial regression 多项式回归我们的线性模型对于数据来说太简单了，导致了欠拟合(高偏差)。在这一部分的练习中，您将通过添加更多的特性来解决这个问题。 使用多项式回归，假设函数形式如下： 3.1 Learning Polynomial Regression数据预处理 X，Xval，Xtest都需要添加多项式特征，这里我们选择增加到6次方，因为若选8次方无法达到作业pdf上的效果图，这是因为scipy和octave版本的优化算法不同。 不要忘了标准化。 12345678910111213141516171819202122def genPolyFeatures(X, power): """添加多项式特征 每次在array的最后一列插入第二列的i+2次方（第一列为偏置） 从二次方开始开始插入（因为本身含有一列一次方） """ Xpoly = X.copy() for i in range(2, power + 1): Xpoly = np.insert(Xpoly, Xpoly.shape[1], np.power(Xpoly[:,1], i), axis=1) return Xpolydef get_means_std(X): """获取训练集的均值和误差，用来标准化所有数据。""" means = np.mean(X,axis=0) stds = np.std(X,axis=0,ddof=1) # ddof=1 means 样本标准差 return means, stdsdef featureNormalize(myX, means, stds): """标准化""" X_norm = myX.copy() X_norm[:,1:] = X_norm[:,1:] - means[1:] X_norm[:,1:] = X_norm[:,1:] / stds[1:] return X_norm 关于归一化，所有数据集应该都用训练集的均值和样本标准差处理。切记。所以要将训练集的均值和样本标准差存储起来，对后面的数据进行处理。 而且注意这里是样本标准差而不是总体标准差，使用np.std()时，将ddof=1则是样本标准差，默认=0是总体标准差。而pandas默认计算样本标准差。 获取添加多项式特征以及 标准化之后的数据。 123456power = 6 # 扩展到x的6次方train_means, train_stds = get_means_std(genPolyFeatures(X,power))X_norm = featureNormalize(genPolyFeatures(X,power), train_means, train_stds)Xval_norm = featureNormalize(genPolyFeatures(Xval,power), train_means, train_stds)Xtest_norm = featureNormalize(genPolyFeatures(Xtest,power), train_means, train_stds) 1234567891011def plot_fit(means, stds, l): """画出拟合曲线""" theta = trainLinearReg(X_norm,y, l) x = np.linspace(-75,55,50) xmat = x.reshape(-1, 1) xmat = np.insert(xmat,0,1,axis=1) Xmat = genPolyFeatures(xmat, power) Xmat_norm = featureNormalize(Xmat, means, stds) plotData() plt.plot(x, Xmat_norm@theta,'b--') 12plot_fit(train_means, train_stds, 0)plot_learning_curve(X_norm, y, Xval_norm, yval, 0) 3.2 Adjusting the regularization parameter上图可以看到 $\lambda$ = 0时，训练误差太小了，明显过拟合了。 我们继续调整$\lambda$ = 1 时： 12plot_fit(train_means, train_stds, 1)plot_learning_curve(X_norm, y, Xval_norm, yval, 1) 我们继续调整$\lambda$ = 100 时，很明显惩罚过多，欠拟合了 12plot_fit(train_means, train_stds, 100)plot_learning_curve(X_norm, y, Xval_norm, yval, 100) 3.3 Selecting λ using a cross validation set1234567891011121314lambdas = [0., 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1., 3., 10.]errors_train, errors_val = [], []for l in lambdas: theta = trainLinearReg(X_norm, y, l) errors_train.append(costReg(theta,X_norm,y,0)) # 记得把lambda = 0 errors_val.append(costReg(theta,Xval_norm,yval,0)) plt.figure(figsize=(8,5))plt.plot(lambdas,errors_train,label='Train')plt.plot(lambdas,errors_val,label='Cross Validation')plt.legend()plt.xlabel('lambda')plt.ylabel('Error')plt.grid(True) 12# 可以看到时交叉验证代价最小的是 lambda = 3lambdas[np.argmin(errors_val)] # 3.0 3.4 Computing test set errorIn our cross validation, we obtained a test error of 3.8599 for λ = 3. 实际上我在上面调整了power=6来匹配作业里面的图，所以得不到3.8599。但是调整power=8时（同作业里一样）,就可以得到上述数据。 12345theta = trainLinearReg(X_norm, y, 3)print('test cost(l=&#123;&#125;) = &#123;&#125;'.format(3, costReg(theta, Xtest_norm, ytest, 0)))# for l in lambdas:# theta = trainLinearReg(X_norm, y, l)# print('test cost(l=&#123;&#125;) = &#123;&#125;'.format(l, costReg(theta, Xtest_norm, ytest, 0))) test cost(l=3) = 4.7552720391599]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达机器学习作业Python实现(四)：神经网络反向传播]]></title>
    <url>%2F2018%2F05%2F21%2F180521-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD)%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[1 Neural Networks 神经网络在这个练习中，你将实现反向传播算法来学习神经网络的参数。依旧是上次预测手写数数字的例子。 1.1 Visualizing the data 可视化数据这部分我们随机选取100个样本并可视化。训练集共有5000个训练样本，每个样本是20*20像素的数字的灰度图像。每个像素代表一个浮点数，表示该位置的灰度强度。20×20的像素网格被展开成一个400维的向量。在我们的数据矩阵X中，每一个样本都变成了一行，这给了我们一个5000×400矩阵X，每一行都是一个手写数字图像的训练样本。 12345import numpy as npimport matplotlib.pyplot as pltfrom scipy.io import loadmatimport scipy.optimize as optfrom sklearn.metrics import classification_report # 这个包是评价报告 1234567def load_mat(path): '''读取数据''' data = loadmat('ex4data1.mat') # return a dict X = data['X'] y = data['y'].flatten() return X, y 1234567891011def plot_100_images(X): """随机画100个数字""" index = np.random.choice(range(5000), 100) images = X[index] fig, ax_array = plt.subplots(10, 10, sharey=True, sharex=True, figsize=(8, 8)) for r in range(10): for c in range(10): ax_array[r, c].matshow(images[r*10 + c].reshape(20,20), cmap='gray_r') plt.xticks([]) plt.yticks([]) plt.show() 12X,y = load_mat('ex4data1.mat')plot_100_images(X) 1.2 Model representation 模型表示我们的网络有三层，输入层，隐藏层，输出层。我们的输入是数字图像的像素值，因为每个数字的图像大小为20*20，所以我们输入层有400个单元（这里不包括总是输出要加一个偏置单元）。 1.2.1 load train data set 读取数据首先我们要将标签值（1，2，3，4，…，10）转化成非线性相关的向量，向量对应位置（y[i-1]）上的值等于1，例如y[0]=6转化为y[0]=[0,0,0,0,0,1,0,0,0,0]。 123456789101112131415from sklearn.preprocessing import OneHotEncoderdef expand_y(y): result = [] # 把y中每个类别转化为一个向量，对应的lable值在向量对应位置上置为1 for i in y: y_array = np.zeros(10) y_array[i-1] = 1 result.append(y_array) ''' # 或者用sklearn中OneHotEncoder函数 encoder = OneHotEncoder(sparse=False) # return a array instead of matrix y_onehot = encoder.fit_transform(y.reshape(-1,1)) return y_onehot ''' return np.array(result) 获取训练数据集，以及对训练集做相应的处理，得到我们的input X，lables y。 1234567raw_X, raw_y = load_mat('ex4data1.mat')X = np.insert(raw_X, 0, 1, axis=1)y = expand_y(raw_y)X.shape, y.shape'''((5000, 401), (5000, 10))''' 1.2.2 load weight 读取权重这里我们提供了已经训练好的参数θ1，θ2，存储在ex4weight.mat文件中。这些参数的维度由神经网络的大小决定，第二层有25个单元，输出层有10个单元(对应10个数字类)。 123def load_weight(path): data = loadmat(path) return data['Theta1'], data['Theta2'] 123t1, t2 = load_weight('ex4weights.mat')t1.shape, t2.shape# ((25, 401), (10, 26)) 1.2.3 展开参数当我们使用高级优化方法来优化神经网络时，我们需要将多个参数矩阵展开，才能传入优化函数，然后再恢复形状。 123def serialize(a, b): '''展开参数''' return np.r_[a.flatten(),b.flatten()] 12theta = serialize(t1, t2) # 扁平化参数，25*401+10*26=10285theta.shape # (10285,) 123def deserialize(seq): '''提取参数''' return seq[:25*401].reshape(25, 401), seq[25*401:].reshape(10, 26) 1.3 Feedforward and cost function 前馈和代价函数1.3.1 Feedforward确保每层的单元数，注意输出时加一个偏置单元，s(1)=400+1，s(2)=25+1，s(3)=10。 12def sigmoid(z): return 1 / (1 + np.exp(-z)) 1234567891011def feed_forward(theta, X,): '''得到每层的输入和输出''' t1, t2 = deserialize(theta) # 前面已经插入过偏置单元，这里就不用插入了 a1 = X z2 = a1 @ t1.T a2 = np.insert(sigmoid(z2), 0, 1, axis=1) z3 = a2 @ t2.T a3 = sigmoid(z3) return a1, z2, a2, z3, a3 1a1, z2, a2, z3, h = feed_forward(theta, X) 1.3.2 Cost function回顾下神经网络的代价函数（不带正则化项） 输出层输出的是对样本的预测，包含5000个数据，每个数据对应了一个包含10个元素的向量，代表了结果有10类。在公式中，每个元素与log项对应相乘。 最后我们使用提供训练好的参数θ，算出的cost应该为0.287629 1234567891011121314def cost(theta, X, y): a1, z2, a2, z3, h = feed_forward(theta, X) J = 0 for i in range(len(X)): first = - y[i] * np.log(h[i]) second = (1 - y[i]) * np.log(1 - h[i]) J = J + np.sum(first - second) J = J / len(X) return J''' # or just use verctorization J = - y * np.log(h) - (1 - y) * np.log(1 - h) return J.sum() / len(X)''' 1cost(theta, X, y) # 0.2876291651613189 1.4 Regularized cost function 正则化代价函数 注意不要将每层的偏置项正则化。 最后You should see that the cost is about 0.383770 12345def regularized_cost(theta, X, y, l=1): '''正则化时忽略每层的偏置项，也就是参数矩阵的第一列''' t1, t2 = deserialize(theta) reg = np.sum(t1[:,1:] ** 2) + np.sum(t2[:,1:] ** 2) # or use np.power(a, 2) return l / (2 * len(X)) * reg + cost(theta, X, y) 1regularized_cost(theta, X, y, 1) # 0.38376985909092354 2 Backpropagation 反向传播2.1 Sigmoid gradient S函数导数 这里可以手动推导，并不难。 12def sigmoid_gradient(z): return sigmoid(z) * (1 - sigmoid(z)) 2.2 Random initialization 随机初始化当我们训练神经网络时，随机初始化参数是很重要的，可以打破数据的对称性。一个有效的策略是在均匀分布(−e，e)中随机选择值，我们可以选择 e = 0.12 这个范围的值来确保参数足够小，使得训练更有效率。 123def random_init(size): '''从服从的均匀分布的范围中随机返回size大小的值''' return np.random.uniform(-0.12, 0.12, size) 2.3 Backpropagation 反向传播 目标：获取整个网络代价函数的梯度。以便在优化算法中求解。 这里面一定要理解正向传播和反向传播的过程，才能弄清楚各种参数在网络中的维度，切记。比如手写出每次传播的式子。 123456789101112print('a1', a1.shape,'t1', t1.shape)print('z2', z2.shape)print('a2', a2.shape, 't2', t2.shape)print('z3', z3.shape)print('a3', h.shape)'''a1 (5000, 401) t1 (25, 401)z2 (5000, 25)a2 (5000, 26) t2 (10, 26)z3 (5000, 10)a3 (5000, 10)''' 1234567891011121314def gradient(theta, X, y): ''' unregularized gradient, notice no d1 since the input layer has no error return 所有参数theta的梯度，故梯度D(i)和参数theta(i)同shape，重要。 ''' t1, t2 = deserialize(theta) a1, z2, a2, z3, h = feed_forward(theta, X) d3 = h - y # (5000, 10) d2 = d3 @ t2[:,1:] * sigmoid_gradient(z2) # (5000, 25) D2 = d3.T @ a2 # (10, 26) D1 = d2.T @ a1 # (25, 401) D = (1 / len(X)) * serialize(D1, D2) # (10285,) return D 2.4 Gradient checking 梯度检测在你的神经网络,你是最小化代价函数J(Θ)。执行梯度检查你的参数,你可以想象展开参数Θ(1)Θ(2)成一个长向量θ。通过这样做,你能使用以下梯度检查过程。 123456789101112131415161718192021def gradient_checking(theta, X, y, e): def a_numeric_grad(plus, minus): """ 对每个参数theta_i计算数值梯度，即理论梯度。 """ return (regularized_cost(plus, X, y) - regularized_cost(minus, X, y)) / (e * 2) numeric_grad = [] for i in range(len(theta)): plus = theta.copy() # deep copy otherwise you will change the raw theta minus = theta.copy() plus[i] = plus[i] + e minus[i] = minus[i] - e grad_i = a_numeric_grad(plus, minus) numeric_grad.append(grad_i) numeric_grad = np.array(numeric_grad) analytic_grad = regularized_gradient(theta, X, y) diff = np.linalg.norm(numeric_grad - analytic_grad) / np.linalg.norm(numeric_grad + analytic_grad) print('If your backpropagation implementation is correct,\nthe relative difference will be smaller than 10e-9 (assume epsilon=0.0001).\nRelative Difference: &#123;&#125;\n'.format(diff)) 1gradient_checking(theta, X, y, epsilon= 0.0001)#这个运行很慢，谨慎运行 2.5 Regularized Neural Networks 正则化神经网络 12345678910def regularized_gradient(theta, X, y, l=1): """不惩罚偏置单元的参数""" a1, z2, a2, z3, h = feed_forward(theta, X) D1, D2 = deserialize(gradient(theta, X, y)) t1[:,0] = 0 t2[:,0] = 0 reg_D1 = D1 + (l / len(X)) * t1 reg_D2 = D2 + (l / len(X)) * t2 return serialize(reg_D1, reg_D2) 2.6 Learning parameters using fmincg 优化参数12345678910def nn_training(X, y): init_theta = random_init(10285) # 25*401 + 10*26 res = opt.minimize(fun=regularized_cost, x0=init_theta, args=(X, y, 1), method='TNC', jac=regularized_gradient, options=&#123;'maxiter': 400&#125;) return res 1234567891011121314res = nn_training(X, y)#慢res''' fun: 0.5156784004838036 jac: array([-2.51032294e-04, -2.11248326e-12, 4.38829369e-13, ..., 9.88299811e-05, -2.59923586e-03, -8.52351187e-04]) message: 'Converged (|f_n-f_(n-1)| ~= 0)' nfev: 271 nit: 17 status: 1 success: True x: array([ 0.58440213, -0.02013683, 0.1118854 , ..., -2.8959637 , 1.85893941, -2.78756836])''' 1234def accuracy(theta, X, y): _, _, _, _, h = feed_forward(res.x, X) y_pred = np.argmax(h, axis=1) + 1 print(classification_report(y, y_pred)) 1234567891011121314151617accuracy(res.x, X, raw_y)''' precision recall f1-score support 1 0.97 0.99 0.98 500 2 0.98 0.97 0.98 500 3 0.98 0.95 0.96 500 4 0.98 0.97 0.97 500 5 0.97 0.98 0.97 500 6 0.99 0.98 0.98 500 7 0.99 0.97 0.98 500 8 0.96 0.98 0.97 500 9 0.97 0.98 0.97 500 10 0.99 0.99 0.99 500avg / total 0.98 0.98 0.98 5000''' 3 Visualizing the hidden layer 可视化隐藏层理解神经网络是如何学习的一个很好的办法是，可视化隐藏层单元所捕获的内容。通俗的说，给定一个的隐藏层单元，可视化它所计算的内容的方法是找到一个输入x，x可以激活这个单元（也就是说有一个激活值 $a^{(l)}_i$ 接近与1）。对于我们所训练的网络，注意到θ1中每一行都是一个401维的向量，代表每个隐藏层单元的参数。如果我们忽略偏置项，我们就能得到400维的向量，这个向量代表每个样本输入到每个隐层单元的像素的权重。因此可视化的一个方法是，reshape这个400维的向量为（20，20）的图像然后输出。 注：It turns out that this is equivalent to finding the input that gives the highest activation for the hidden unit, given a norm constraint on the input. 这相当于找到了一个输入，给了隐层单元最高的激活值，给定了一个输入的标准限制。例如( $||x||_2 \leq 1$) (这部分暂时不太理解) 12345678910def plot_hidden(theta): t1, _ = deserialize(theta) t1 = t1[:, 1:] fig,ax_array = plt.subplots(5, 5, sharex=True, sharey=True, figsize=(6,6)) for r in range(5): for c in range(5): ax_array[r, c].matshow(t1[r * 5 + c].reshape(20, 20), cmap='gray_r') plt.xticks([]) plt.yticks([]) plt.show() 1plot_hidden(res.x) 在我们经过训练的网络中，你应该发现隐藏的单元大致对应于在输入中寻找笔画和其他模式的检测器。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BP神经网络(反向传播)详细推导]]></title>
    <url>%2F2018%2F05%2F21%2F180521-BP%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD)%E8%AF%A6%E7%BB%86%E6%8E%A8%E5%AF%BC%2F</url>
    <content type="text"><![CDATA[这篇文章主要讨论神经网络的反向传播的细节，“误差”是如何反向传播的，我们又是如何利用梯度来优化参数的。 在学吴恩达机器学习视频的神经网络那节时，给出了许多公式，比如计算每层的误差，每层参数的梯度，但并没有给出推导过程，可能也是考虑入门级，大多人并不要知道其中含义就可以运用算法了。接下来我会给出详细的推导过程，帮助大家理解。 注意接下来所讲是未正则化的神经网络。 1 计算公式1.1 正向传递假设现在有一个三层的神经网络，如图： 参数含义： $\theta^{(i)}$ 第 $i$ 层的参数矩阵 $z^{(l)}$ 第 $l$ 层的输入 $a^{(l)}$ 第 $l$ 层的输出 传递过程： $a^{(1)}=x​$ $z^{(2)}=\theta^{(1)}a^{(1)}$ $a^{(2)}=g(z^{(2)}) (add\;a_0^{(2)})$ $z^{(3)}=\theta^{(2)}a^{(2)}$ $h=a^{(3)}=g(z^{(3)})$ 其中$g$ 为sigmoid激活函数。 1.2 反向传播我们用$\delta^{(l)}$ 表示每层的”误差“，$y$ 为每个样本的标签，$h$ 为每个样本的预测值。 先来从后往前计算每层的“误差“。注意到这里的误差用双引号括起来，因为并不是真正的误差。 $\delta^{(3)}=h-y$ (1) $\delta^{(2)}=(\theta^{(2)})^T\delta^{(3)}g^{‘}(z^{(2)})$ (2) 注意第一层是没有误差的，因为是输入层。 吴恩达在课里面提到，”误差“的实质是 $\delta^{(l)}=\frac{\partial J}{\partial z^{(l)}}$ ，没错，后面详细说明。 然后来计算每层参数矩阵的梯度，用$\Delta^{(l)}$ 表示 $\Delta^{(2)}=a^{(2)}\delta^{(3)}$ (3) $\Delta^{(1)}=a^{(1)}\delta^{(2)}$ (4) 最后网络的总梯度为： $D=\frac{1}{m}(\Delta^{(1)}+\Delta^{(2)})$ (5) 到这里反向传播就完成了，接着就可以利用梯度下降法或者更高级的优化算法来训练网络。 2 推导这里只推导 $\delta\;和\;\Delta$ 是怎么来的，其余的比较好理解。 首先明确我们要优化的参数有 $\theta^{(1)}$，$\theta^{(2)}$ ，利用梯度下降法的思想，我们只需要求解出代价函数对参数的梯度即可。 假设只有一个输入样本，则代价函数是：$$J(\theta)=-ylogh(x)-(1-y)log(1-h)$$回顾下正向传递的过程，理解其中函数的嵌套关系： $a^{(1)}=x​$ $z^{(2)}=\theta^{(1)}a^{(1)}$ $a^{(2)}=g(z^{(2)}) (add\;a_0^{(2)})$ $z^{(3)}=\theta^{(2)}a^{(2)}$ $h=a^{(3)}=g(z^{(3)})$ 然后我们来求解代价函数对参数的梯度，$\frac{\partial}{\partial \theta^{(2)}}J(\theta)$ ，$\frac{\partial}{\partial \theta^{(1)}}J(\theta)$ 。 根据链式求导法则，可以计算得到： 把我画红线的地方令为$\delta^{(3)}$ ，是不是就得到了反向传播中的公式（1）？ 把画绿线的部分令为$\Delta^{(2)}$ ，就得到了公式（3）。我们接着算： 同样把红线部分令为$\delta^{(3)}$ ，紫色部分令为$\delta^{(2)}$ ，就得到了公式（2）。 绿线部分令为$\Delta^{(1)}$ ，就得到了公式（4）。 至此，推导完毕。得到这个规律后，便可以应用到深层次的网络中，计算反向传播时就很方便了。 上面的公式因为书写麻烦，便只写了结果。如果你用笔去慢慢推几分钟，会发现其实很简单。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达机器学习作业Python实现(三)：多类分类和前馈神经网络]]></title>
    <url>%2F2018%2F05%2F18%2F180518-logistic%E5%A4%9A%E7%B1%BB%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[在此练习中，我们将使用logistic回归和神经网络来识别手写数字（0到9）。 1 多类分类(多个logistic回归)我们将扩展我们在练习2中写的logistic回归的实现，并将其应用于一对多的分类（不止两个类别）。 1234import numpy as npimport pandas as pdimport matplotlib.pyplot as pltfrom scipy.io import loadmat Dataset首先，加载数据集。这里的数据为MATLAB的格式，所以要使用SciPy.io的loadmat函数。 12345def load_data(path): data = loadmat(path) X = data['X'] y = data['y'] return X,y 12345X, y = load_data('ex3data1.mat')print(np.unique(y)) # 看下有几类标签# [ 1 2 3 4 5 6 7 8 9 10]X.shape, y.shape# ((5000, 400), (5000, 1)) 其中有5000个训练样本，每个样本是20*20像素的数字的灰度图像。每个像素代表一个浮点数，表示该位置的灰度强度。20×20的像素网格被展开成一个400维的向量。在我们的数据矩阵X中，每一个样本都变成了一行，这给了我们一个5000×400矩阵X，每一行都是一个手写数字图像的训练样本。 第一个任务是将我们的逻辑回归实现修改为完全向量化（即没有“for”循环）。这是因为向量化代码除了简洁外，还能够利用线性代数优化，并且通常比迭代代码快得多。 1.2 Visualizing the data123456789101112def plot_an_image(X): """ 随机打印一个数字 """ pick_one = np.random.randint(0, 5000) image = X[pick_one, :] fig, ax = plt.subplots(figsize=(1, 1)) ax.matshow(image.reshape((20, 20)), cmap='gray_r') plt.xticks([]) # 去除刻度，美观 plt.yticks([]) plt.show() print('this should be &#123;&#125;'.format(y[pick_one])) 12345678910111213141516def plot_100_image(X): """ 随机画100个数字 """ sample_idx = np.random.choice(np.arange(X.shape[0]), 100) # 随机选100个样本 sample_images = X[sample_idx, :] # (100,400) fig, ax_array = plt.subplots(nrows=10, ncols=10, sharey=True, sharex=True, figsize=(8, 8)) for row in range(10): for column in range(10): ax_array[row, column].matshow(sample_images[10 * row + column].reshape((20, 20)), cmap='gray_r') plt.xticks([]) plt.yticks([]) plt.show() 1.3 Vectorizing Logistic Regression我们将使用多个one-vs-all(一对多)logistic回归模型来构建一个多类分类器。由于有10个类，需要训练10个独立的分类器。为了提高训练效率，重要的是向量化。在本节中，我们将实现一个不使用任何for循环的向量化的logistic回归版本。 首先准备下数据。 1.3.1 Vectorizing the cost function首先写出向量化的代价函数。回想正则化的logistic回归的代价函数是： $$ J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{[-{{y}^{(i)}}\log \left( {{h}_{\theta }}\left( {{x}^{(i)}} \right) \right)-\left( 1-{{y}^{(i)}} \right)\log \left( 1-{{h}_{\theta }}\left( {{x}^{(i)}} \right) \right)]}+\frac{\lambda}{2m}\sum^n_{j=1}\theta^2_j $$ 首先我们对每个样本 $i$ 要计算$h_{\theta}(x^{(i)})$，$h_{\theta}(x^{(i)})=g(\theta^Tx^{(i)})$，$g(z)=\frac{1}{1+e^{-z}}$ sigmoid函数。 事实上我们可以对所有的样本用矩阵乘法来快速的计算。让我们如下来定义 $X$ 和 $\theta$ ： 然后通过计算矩阵积 $X\theta$ ，我们可以得到： 在最后一个等式中，我们用到了一个定理，如果 $a$ 和 $b$ 都是向量，那么 $a^Tb=b^Ta$，这样我们就可以用一行代码计算出所有的样本。 12def sigmoid(z): return 1 / (1 + np.exp(-z)) 123456789101112def regularized_cost(theta, X, y, l): """ don't penalize theta_0 args: X: feature matrix, (m, n+1) # 插入了x0=1 y: target vector, (m, ) l: lambda constant for regularization """ thetaReg = theta[1:] first = (-y*np.log(sigmoid(X@theta))) + (y-1)*np.log(1-sigmoid(X@theta)) reg = (thetaReg@thetaReg)*l / (2*len(X)) return np.mean(first) + reg 1.3.2 Vectorizing the gradient回顾正则化logistic回归代价函数的梯度下降法如下表示，因为不惩罚theta_0，所以分为两种情况： 所以其中的梯度表示如下： 12345678910111213def regularized_gradient(theta, X, y, l): """ don't penalize theta_0 args: l: lambda constant return: a vector of gradient """ thetaReg = theta[1:] first = (1 / len(X)) * X.T @ (sigmoid(X @ theta) - y) # 这里人为插入一维0，使得对theta_0不惩罚，方便计算 reg = np.concatenate([np.array([0]), (l / len(X)) * thetaReg]) return first + reg 1.4 One-vs-all Classification这部分我们将实现一对多分类通过训练多个正则化logistic回归分类器，每个对应数据集中K类中的一个。 对于这个任务，我们有10个可能的类，并且由于logistic回归只能一次在2个类之间进行分类，每个分类器在“类别 i”和“不是 i”之间决定。 我们将把分类器训练包含在一个函数中，该函数计算10个分类器中的每个分类器的最终权重，并将权重返回shape为(k, (n+1))数组，其中 n 是参数数量。 12345678910111213141516171819202122from scipy.optimize import minimizedef one_vs_all(X, y, l, K): """generalized logistic regression args: X: feature matrix, (m, n+1) # with incercept x0=1 y: target vector, (m, ) l: lambda constant for regularization K: numbel of labels return: trained parameters """ all_theta = np.zeros((K, X.shape[1])) # (10, 401) for i in range(1, K+1): theta = np.zeros(X.shape[1]) y_i = np.array([1 if label == i else 0 for label in y]) ret = minimize(fun=regularized_cost, x0=theta, args=(X, y_i, l), method='TNC', jac=regularized_gradient, options=&#123;'disp': True&#125;) all_theta[i-1,:] = ret.x return all_theta 这里需要注意的几点：首先，我们为X添加了一列常数项 1 ，以计算截距项（常数项）。 其次，我们将y从类标签转换为每个分类器的二进制值（要么是类i，要么不是类i）。 最后，我们使用SciPy的较新优化API来最小化每个分类器的代价函数。 如果指定的话，API将采用目标函数，初始参数集，优化方法和jacobian（渐变）函数。 然后将优化程序找到的参数分配给参数数组。 实现向量化代码的一个更具挑战性的部分是正确地写入所有的矩阵，保证维度正确。 12345678910def predict_all(X, all_theta): # compute the class probability for each class on each training instance h = sigmoid(X @ all_theta.T) # 注意的这里的all_theta需要转置 # create array of the index with the maximum probability # Returns the indices of the maximum values along an axis. h_argmax = np.argmax(h, axis=1) # because our array was zero-indexed we need to add one for the true label prediction h_argmax = h_argmax + 1 return h_argmax 这里的h共5000行，10列，每行代表一个样本，每列是预测对应数字的概率。我们取概率最大对应的index加1就是我们分类器最终预测出来的类别。返回的h_argmax是一个array，包含5000个样本对应的预测值。 123456raw_X, raw_y = load_data('ex3data1.mat')X = np.insert(raw_X, 0, 0, axis=1) # (5000, 401)y = raw_y.flatten() # 这里消除了一个维度，方便后面的计算 or .reshape(-1) （5000，）all_theta = one_vs_all(X, y, 1, 10)all_theta # 每一行是一个分类器的一组参数 123y_pred = predict_all(X, all_theta)accuracy = np.mean(y_pred == y)print ('accuracy = &#123;0&#125;%'.format(accuracy * 100)) Tips: python中 true就是1，1就是true，false就是0，0就是false 2 Neural Networks上面使用了多类logistic回归，然而logistic回归不能形成更复杂的假设，因为它只是一个线性分类器。 接下来我们用神经网络来尝试下，神经网络可以实现非常复杂的非线性的模型。我们将利用已经训练好了的权重进行预测。 123def load_weight(path): data = loadmat(path) return data['Theta1'], data['Theta2'] 123theta1, theta2 = load_weight('ex3weights.mat')theta1.shape, theta2.shape 12345X, y = load_data('ex3data1.mat')y = y.flatten()X = np.insert(X, 0, values=np.ones(X.shape[0]), axis=1) # interceptX.shape, y.shape 123a1 = Xz2 = a1 @ theta1.Tz2.shape 1z2 = np.insert(z2, 0, 1, axis=1) 12a2 = sigmoid(z2)a2.shape 12z3 = a2 @ theta2.Tz3.shape 12a3 = sigmoid(z3)a3.shape 123y_pred = np.argmax(a3, axis=1) + 1 accuracy = np.mean(y_pred == y)print ('accuracy = &#123;0&#125;%'.format(accuracy * 100)) # accuracy = 97.52% 虽然人工神经网络是非常强大的模型，但训练数据的准确性并不能完美预测实际数据，在这里很容易过拟合。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达机器学习作业Python实现(二)：logistic回归]]></title>
    <url>%2F2018%2F05%2F18%2F180523-logistic%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[1 Logistic regression在这部分的练习中，你将建立一个逻辑回归模型来预测一个学生是否能进入大学。假设你是一所大学的行政管理人员，你想根据两门考试的结果，来决定每个申请人是否被录取。你有以前申请人的历史数据，可以将其用作逻辑回归训练集。对于每一个训练样本，你有申请人两次测评的分数以及录取的结果。为了完成这个预测任务，我们准备构建一个可以基于两次测试评分来评估录取可能性的分类模型。 1.1 Visualizing the data在开始实现任何学习算法之前，如果可能的话，最好将数据可视化。 1234%matplotlib inlineimport numpy as npimport pandas as pdimport matplotlib.pyplot as plt 12data = pd.read_csv(&apos;ex2data1.txt&apos;, names=[&apos;exam1&apos;, &apos;exam2&apos;, &apos;admitted&apos;])data.head() 1data.describe() 让我们创建两个分数的散点图，并使用颜色编码来可视化，如果样本是正的（被接纳）或负的（未被接纳）。 1234567891011121314positive = data[data.admitted.isin([&apos;1&apos;])] # 1negetive = data[data.admitted.isin([&apos;0&apos;])] # 0fig, ax = plt.subplots(figsize=(6,5))ax.scatter(positive[&apos;exam1&apos;], positive[&apos;exam2&apos;], c=&apos;b&apos;, label=&apos;Admitted&apos;)ax.scatter(negetive[&apos;exam1&apos;], negetive[&apos;exam2&apos;], s=50, c=&apos;r&apos;, marker=&apos;x&apos;, label=&apos;Not Admitted&apos;)# 设置图例显示在图的上方box = ax.get_position()ax.set_position([box.x0, box.y0, box.width , box.height* 0.8])ax.legend(loc=&apos;center left&apos;, bbox_to_anchor=(0.2, 1.12),ncol=3)# 设置横纵坐标名ax.set_xlabel(&apos;Exam 1 Score&apos;)ax.set_ylabel(&apos;Exam 2 Score&apos;)plt.show() 看起来在两类间，有一个清晰的决策边界。现在我们需要实现逻辑回归，那样就可以训练一个模型来预测结果。 1.2 Sigmoid function 首先来回顾下 logistic回归的假设函数： $${{h}_{\theta }}\left( x \right)=g(\theta^{T}x)=\frac{1}{1+{{e}^{-{{\theta }^{T}}X}}}$$ 其中的 g代表一个常用的logistic function为S形函数（Sigmoid function）： $$g\left( z \right)=\frac{1}{1+e^{-z}}$$ 12def sigmoid(z): return 1 / (1 + np.exp(- z)) 让我们做一个快速的检查，来确保它可以工作。 123x1 = np.arange(-10, 10, 0.1)plt.plot(x1, sigmoid(x1), c=&apos;r&apos;)plt.show() 感觉很不错~~~ 1.3 Cost function逻辑回归的代价函数如下，和线性回归的代价函数不一样，因为这个函数是凸的。 $$J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{[-{{y}^{(i)}}\log \left( {{h}_{\theta }}\left( {{x}^{(i)}} \right) \right)-\left( 1-{{y}^{(i)}} \right)\log \left( 1-{{h}_{\theta }}\left( {{x}^{(i)}} \right) \right)]}$$ $${{h}_{\theta }}\left( x \right)=g(\theta^{T}x)$$ 1234def cost(theta, X, y): first = (-y) * np.log(sigmoid(X @ theta)) second = (1 - y)*np.log(1 - sigmoid(X @ theta)) return np.mean(first - second) 现在，我们要做一些设置，获取我们的训练集数据。 123456789# add a ones column - this makes the matrix multiplication work out easierif &apos;Ones&apos; not in data.columns: data.insert(0, &apos;Ones&apos;, 1)# set X (training data) and y (target variable)X = data.iloc[:, :-1].as_matrix() # Convert the frame to its Numpy-array representation.y = data.iloc[:, -1].as_matrix() # Return is NOT a Numpy-matrix, rather, a Numpy-array.theta = np.zeros(X.shape[1]) 让我们来检查矩阵的维度，确保一切良好。 12X.shape, theta.shape, y.shape# ((100, 3), (3,), (100,)) 12cost(theta, X, y)# 0.6931471805599453 看起来不错，接下来，我们需要一个函数来计算我们的训练数据、标签和一些参数thate的梯度。 1.4 Gradient * 这是批量梯度下降（batch gradient descent） * 转化为向量化计算： $\frac{1}{m} X^T( Sigmoid(X\theta) - y )$ $$\frac{\partial J\left( \theta \right)}{\partial {{\theta }_{j}}}=\frac{1}{m}\sum\limits_{i=1}^{m}{({{h}_{\theta }}\left( {{x}^{(i)}} \right)-{{y}^{(i)}})x_{_{j}}^{(i)}}$$ 123def gradient(theta, X, y): return (X.T @ (sigmoid(X @ theta) - y))/len(X) # the gradient of the cost is a vector of the same length as θ where the jth element (for j = 0, 1, . . . , n) 12gradient(theta, X, y)# array([ -0.1, -12.00921659, -11.26284221]) 1.5 Learning θ parameters注意，我们实际上没有在这个函数中执行梯度下降，我们仅仅在计算梯度。在练习中，一个称为“fminunc”的Octave函数是用来优化函数来计算成本和梯度参数。由于我们使用Python，我们可以用SciPy的“optimize”命名空间来做同样的事情。 这里我们使用的是高级优化算法，运行速度通常远远超过梯度下降。方便快捷。只需传入cost函数，已经所求的变量theta，和梯度。cost函数定义变量时变量tehta要放在第一个，若cost函数只返回cost，则设置fprime=gradient。 1import scipy.optimize as opt 这里使用fimin_tnc或者minimize方法来拟合，minimize中method可以选择不同的算法来计算，其中包括TNC 1234result = opt.fmin_tnc(func=cost, x0=theta, fprime=gradient, args=(X, y))result# (array([-25.16131867, 0.20623159, 0.20147149]), 36, 0) 下面是第二种方法，结果是一样的1234res = opt.minimize(fun=cost, x0=theta, args=(X, y), method=&apos;TNC&apos;, jac=gradient)res# help(opt.minimize) # res.x # final_theta fun: 0.2034977015894744 jac: array([9.11457705e-09, 9.59621025e-08, 4.84073722e-07]) message: &apos;Local minimum reached (|pg| ~= 0)&apos; nfev: 36 nit: 17 status: 0 success: True x: array([-25.16131867, 0.20623159, 0.20147149]) 1cost(result[0], X, y) 0.2034977015894744 1.6 Evaluating logistic regression学习好了参数θ后，我们来用这个模型预测某个学生是否能被录取。 接下来，我们需要编写一个函数，用我们所学的参数theta来为数据集X输出预测。然后，我们可以使用这个函数来给我们的分类器的训练精度打分。 逻辑回归模型的假设函数： ${{h}_{\theta }}\left( x \right)=\frac{1}{1+{{e}^{-{{\theta }^{T}}X}}}$ 当${{h}_{\theta }}$大于等于0.5时，预测 y=1 当${{h}_{\theta }}$小于0.5时，预测 y=0 。 123def predict(theta, X): probability = sigmoid(X@theta) return [1 if x &gt;= 0.5 else 0 for x in probability] # return a list 12345final_theta = result[0]predictions = predict(final_theta, X)correct = [1 if a==b else 0 for (a, b) in zip(predictions, y)]accuracy = sum(correct) / len(X)accuracy 0.89 可以看到我们预测精度达到了89%，not bad. 也可以用skearn中的方法来检验。 12from sklearn.metrics import classification_reportprint(classification_report(predictions, y)) precision recall f1-score support 0 0.85 0.87 0.86 39 1 0.92 0.90 0.91 61 avg / total 0.89 0.89 0.89 100 ​ 1.7 Decision boundary（决策边界）$X \times \theta = 0$ (this is the line) $\theta_0 + x_1\theta_1 + x_2\theta_2=0$ 12x1 = np.arange(130, step=0.1)x2 = -(final_theta[0] + x1*final_theta[1]) / final_theta[2] 12345678910fig, ax = plt.subplots(figsize=(8,5))ax.scatter(positive[&apos;exam1&apos;], positive[&apos;exam2&apos;], c=&apos;b&apos;, label=&apos;Admitted&apos;)ax.scatter(negetive[&apos;exam1&apos;], negetive[&apos;exam2&apos;], s=50, c=&apos;r&apos;, marker=&apos;x&apos;, label=&apos;Not Admitted&apos;)ax.plot(x1, x2)ax.set_xlim(0, 130)ax.set_ylim(0, 130)ax.set_xlabel(&apos;x1&apos;)ax.set_ylabel(&apos;x2&apos;)ax.set_title(&apos;Decision Boundary&apos;)plt.show() 2 Regularized logistic regression在训练的第二部分，我们将要通过加入正则项提升逻辑回归算法。简而言之，正则化是成本函数中的一个术语，它使算法更倾向于“更简单”的模型（在这种情况下，模型将更小的系数）。这个理论助于减少过拟合，提高模型的泛化能力。这样，我们开始吧。 设想你是工厂的生产主管，你有一些芯片在两次测试中的测试结果。对于这两次测试，你想决定是否芯片要被接受或抛弃。为了帮助你做出艰难的决定，你拥有过去芯片的测试数据集，从其中你可以构建一个逻辑回归模型。 2.1 Visualizing the data12data2 = pd.read_csv(&apos;ex2data2.txt&apos;, names=[&apos;Test 1&apos;, &apos;Test 2&apos;, &apos;Accepted&apos;])data2.head() 123456789101112def plot_data(): positive = data2[data2[&apos;Accepted&apos;].isin([1])] negative = data2[data2[&apos;Accepted&apos;].isin([0])] fig, ax = plt.subplots(figsize=(8,5)) ax.scatter(positive[&apos;Test 1&apos;], positive[&apos;Test 2&apos;], s=50, c=&apos;b&apos;, marker=&apos;o&apos;, label=&apos;Accepted&apos;) ax.scatter(negative[&apos;Test 1&apos;], negative[&apos;Test 2&apos;], s=50, c=&apos;r&apos;, marker=&apos;x&apos;, label=&apos;Rejected&apos;) ax.legend() ax.set_xlabel(&apos;Test 1 Score&apos;) ax.set_ylabel(&apos;Test 2 Score&apos;) plot_data() 注意到其中的正负两类数据并没有线性的决策界限。因此直接用logistic回归在这个数据集上并不能表现良好，因为它只能用来寻找一个线性的决策边界。 所以接下会提到一个新的方法。 2.2 Feature mapping一个拟合数据的更好的方法是从每个数据点创建更多的特征。 我们将把这些特征映射到所有的x1和x2的多项式项上，直到第六次幂。 https://www.zhihu.com/question/65020904123for i in 0..power for p in 0..i: output x1^(i-p) * x2^p $${\rm{mapFeature}}(x)=\begin{bmatrix} {1}\\ {x_1}\\ {x_2}\\ {x_1^2}\\ {x1x2}\\ {x_2^2}\\ {x_1^3}\\ \vdots\\ {x_1x_2^5}\\ {x_2^6} \end{bmatrix}$$ 1234567891011def feature_mapping(x1, x2, power): data = &#123;&#125; for i in np.arange(power + 1): for p in np.arange(i + 1): data["f&#123;&#125;&#123;&#125;".format(i - p, p)] = np.power(x1, i - p) * np.power(x2, p)# data = &#123;"f&#123;&#125;&#123;&#125;".format(i - p, p): np.power(x1, i - p) * np.power(x2, p)# for i in np.arange(power + 1)# for p in np.arange(i + 1)# &#125; return pd.DataFrame(data) 12x1 = data2[&apos;Test 1&apos;].as_matrix()x2 = data2[&apos;Test 2&apos;].as_matrix() 12_data2 = feature_mapping(x1, x2, power=6)_data2.head() 经过映射，我们将有两个特征的向量转化成了一个28维的向量。 在这个高维特征向量上训练的logistic回归分类器将会有一个更复杂的决策边界，当我们在二维图中绘制时，会出现非线性。 虽然特征映射允许我们构建一个更有表现力的分类器，但它也更容易过拟合。在接下来的练习中，我们将实现正则化的logistic回归来拟合数据，并且可以看到正则化如何帮助解决过拟合的问题。 2.3 Regularized Cost function $$J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{[-{{y}^{(i)}}\log \left( {{h}_{\theta }}\left( {{x}^{(i)}} \right) \right)-\left( 1-{{y}^{(i)}} \right)\log \left( 1-{{h}_{\theta }}\left( {{x}^{(i)}} \right) \right)]}+\frac{\lambda }{2m}\sum\limits_{j=1}^{n}{\theta _{j}^{2}}$$ 注意：不惩罚第一项$\theta_0$ 先获取特征，标签以及参数theta，确保维度良好。 12345# 这里因为做特征映射的时候已经添加了偏置项，所以不用手动添加了。X = _data2.as_matrix() y = data2['Accepted'].as_matrix()theta = np.zeros(X.shape[1])X.shape, y.shape, theta.shape # ((118, 28), (118,), (28,)) costReg(theta, X, y, l123456def costReg(theta, X, y, l=1): # 不惩罚第一项 _theta = theta[1: ] reg = (l / (2 * len(X))) *(_theta @ _theta) # _theta@_theta == inner product return cost(theta, X, y) + reg 1costReg(theta, X, y, l=1) # 0.6931471805599454 2.4 Regularized gradient 因为我们未对${{\theta }_{0}}$ 进行正则化，所以梯度下降算法将分两种情形： \begin{align} & Repeat\text{ }until\text{ }convergence\text{ }\!\!\{\!\!\text{ } \\ & \text{ }{{\theta }_{0}}:={{\theta }_{0}}-a\frac{1}{m}\sum\limits_{i=1}^{m}{[{{h}_{\theta }}\left( {{x}^{(i)}} \right)-{{y}^{(i)}}]x_{_{0}}^{(i)}} \\ & \text{ }{{\theta }_{j}}:={{\theta }_{j}}-a\frac{1}{m}\sum\limits_{i=1}^{m}{[{{h}_{\theta }}\left( {{x}^{(i)}} \right)-{{y}^{(i)}}]x_{j}^{(i)}}+\frac{\lambda }{m}{{\theta }_{j}} \\ & \text{ }\!\!\}\!\!\text{ } \\ & Repeat \\ \end{align} 对上面的算法中 j=1,2,...,n 时的更新式子进行调整可得： ${{\theta }_{j}}:={{\theta }_{j}}(1-a\frac{\lambda }{m})-a\frac{1}{m}\sum\limits_{i=1}^{m}{({{h}_{\theta }}\left( {{x}^{(i)}} \right)-{{y}^{(i)}})x_{j}^{(i)}}$ 同样不惩罚第一个θ 1234def gradientReg(theta, X, y, l=1): reg = (1 / len(X)) * theta reg[0] = 0 return gradient(theta, X, y) + reg 1gradientReg(theta, X, y, 1) array([8.47457627e-03, 8.47457627e-03, 7.77711864e-05, 3.76648474e-02, 2.34764889e-02, 3.93028171e-02, 3.10079849e-02, 3.87936363e-02, 1.87880932e-02, 1.15013308e-02, 8.19244468e-03, 3.09593720e-03, 4.47629067e-03, 1.37646175e-03, 5.03446395e-02, 7.32393391e-03, 1.28600503e-02, 5.83822078e-03, 7.26504316e-03, 1.83559872e-02, 2.23923907e-03, 3.38643902e-03, 4.08503006e-04, 3.93486234e-02, 4.32983232e-03, 6.31570797e-03, 1.99707467e-02, 1.09740238e-03]) 2.5 Learning parameters12result2 = opt.fmin_tnc(func=costReg, x0=theta, fprime=gradientReg, args=(X, y, 2))result2 (array([ 0.57761135, 0.47056293, 1.09213933, -0.93555548, -0.15107417, -0.96567576, -0.49622178, -0.87226365, 0.5986215 , -0.47857791, -0.19652206, -0.10212812, -0.1513566 , -0.03407832, -1.868297 , -0.25062387, -0.49045048, -0.20293012, -0.26033467, 0.02385201, -0.0290203 , -0.0543879 , 0.01131411, -1.39767636, -0.16559351, -0.24745221, -0.29518657, 0.00854288]), 57, 4) 我们还可以使用高级Python库scikit-learn来解决这个问题。 123from sklearn import linear_model#调用sklearn的线性回归包model = linear_model.LogisticRegression(penalty=&apos;l2&apos;, C=1.0)model.fit(X, y.ravel()) LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, max_iter=100, multi_class=&apos;ovr&apos;, n_jobs=1, penalty=&apos;l2&apos;, random_state=None, solver=&apos;liblinear&apos;, tol=0.0001, verbose=0, warm_start=False) 1model.score(X, y) # 0.8305084745762712 2.6 Evaluating logistic regression12345final_theta = result2[0]predictions = predict(final_theta, X)correct = [1 if a==b else 0 for (a, b) in zip(predictions, y)]accuracy = sum(correct) / len(correct)accuracy 0.8135593220338984 或者用skearn中的方法来评估结果。 12345678910print(classification_report(y, predictions))''' precision recall f1-score support 0 0.87 0.75 0.80 60 1 0.77 0.88 0.82 58 avg / total 0.82 0.81 0.81 118 ''' 可以看到和skearn中的模型精确度差不多，这很不错。 2.6 Decision boundary（决策边界）$X \times \theta = 0$ (this is the line) 12345678910x = np.linspace(-1, 1.5, 250)xx, yy = np.meshgrid(x, x)z = feature_mapping(xx.ravel(), yy.ravel(), 6).as_matrix()z = z @ final_thetaz = z.reshape(xx.shape)plot_data()plt.contour(xx, yy, z, 0)plt.ylim(-.8, 1.2)]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达机器学习作业Python实现(一)：线性回归]]></title>
    <url>%2F2018%2F05%2F18%2F180523-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[单变量线性回归在本部分的练习中，您将使用一个变量实现线性回归，以预测食品卡车的利润。假设你是一家餐馆的首席执行官，正在考虑不同的城市开设一个新的分店。该连锁店已经在各个城市拥有卡车，而且你有来自城市的利润和人口数据。您希望使用这些数据来帮助您选择将哪个城市扩展到下一个城市。 12345%matplotlib inlineimport numpy as npimport pandas as pdimport matplotlib.pyplot as plt 导入数据，并查看 1234path = 'ex1data1.txt'# names添加列名，header用指定的行来作为标题，若原无标题且指定标题则设为Nonedata = pd.read_csv(path, header=None, names=['Population', 'Profit']) data.head() 1data.describe() 在开始任何任务之前，通过可视化来理解数据通常是有用的。对于这个数据集，您可以使用散点图来可视化数据，因为它只有两个属性(利润和人口)。(你在现实生活中遇到的许多其他问题都是多维度的，不能在二维图上画出来。) 12data.plot(kind='scatter', x='Population', y='Profit', figsize=(8,5))plt.show() 现在让我们使用梯度下降来实现线性回归，以最小化成本函数。 以下代码示例中实现的方程在“练习”文件夹中的“ex1.pdf”中有详细说明。 首先，我们将创建一个以参数θ为特征函数的代价函数 $$J\left( \theta \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{{{\left( {{h}_{\theta }}\left( {{x}^{(i)}} \right)-{{y}^{(i)}} \right)}^{2}}}$$ 其中：${{h}_{\theta }}\left( x \right)={{\theta }^{T}}X={{\theta }_{0}}{{x}_{0}}+{{\theta }_{1}}{{x}_{1}}+{{\theta }_{2}}{{x}_{2}}+...+{{\theta }_{n}}{{x}_{n}}$ 计算代价函数 $J(\theta)$ 123def computeCost(X, y, theta): inner = np.power(((X * theta.T) - y), 2) return np.sum(inner) / (2 * len(X)) 让我们在训练集中添加一列，以便我们可以使用向量化的解决方案来计算代价和梯度。 1data.insert(0, 'Ones', 1) 现在我们来做一些变量初始化。 取最后一列为 y，其余为 X 1234# set X (training data) and y (target variable)cols = data.shape[1] # 列数X = data.iloc[:,0:cols-1] # 取前cols-1列，即输入向量y = data.iloc[:,cols-1:cols] # 取最后一列，即目标向量 观察下 X (训练集) and y (目标变量)是否正确. 1X.head() # head()是观察前5行 1y.head() 注意：这里我使用的是matix而不是array，两者基本通用。 但是matrix的优势就是相对简单的运算符号，比如两个矩阵相乘，就是用符号*，但是array相乘不能这么用，得用方法.dot()array的优势就是不仅仅表示二维，还能表示3、4、5…维，而且在大部分Python程序里，array也是更常用的。 两者区别： 对应元素相乘：matrix可以用np.multiply(X2,X1)，array直接X1*X2 点乘：matrix直接X1*X2，array可以 X1@X2 或 X1.dot(X2) 或 np.dot(X1, X2) 代价函数是应该是numpy矩阵，所以我们需要转换X和Y，然后才能使用它们。 我们还需要初始化theta。 123X = np.matrix(X.values)y = np.matrix(y.values)theta = np.matrix([0,0]) theta 是一个(1,2)矩阵 12np.array([[0,0]]).shape # (1, 2) 看下维度，确保计算没问题 12X.shape, theta.shape, y.shape# ((97, 2), (1, 2), (97, 1)) 计算初始代价函数的值 (theta初始值为0). 1computeCost(X, y, theta) # 32.072733877455676 batch gradient decent（批量梯度下降） $$ J\left( \theta \right)=\frac{1}{2m}\sum\limits{i=1}^{m}{{{\left( {{h}{\theta }}\left( {{x}^{(i)}} \right)-{{y}^{(i)}} \right)}^{2}}} $$ 其中： $$ {{h}_{\theta }}\left( x \right)={{\theta }^{T}}X={{\theta }_{0}}{{x}_{0}}+{{\theta }_{1}}{{x}_{1}}+{{\theta }_{2}}{{x}_{2}}+...+{{\theta }_{n}}{{x}_{n}} $$ 优化： $$ {{\theta }_{j}}:={{\theta }_{j}}-\alpha \frac{\partial }{\partial {{\theta }_{j}}}J\left( \theta \right) $$ $$\theta_j:=\theta_j-\alpha\frac{1}{m}\sum^{m}{i=1}(h\theta(x^{(i)}) - y^{(i)})x_j^{(i)}$$使用 vectorization同时更新所有的 θ，可以大大提高效率 12X.shape, theta.shape, y.shape, X.shape[0]# ((97, 2), (1, 2), (97, 1), 97) 1234567891011121314151617181920212223def gradientDescent(X, y, theta, alpha, epoch): """reuturn theta, cost""" temp = np.matrix(np.zeros(theta.shape)) # 初始化一个 θ 临时矩阵(1, 2) parameters = int(theta.flatten().shape[1]) # 参数 θ的数量 cost = np.zeros(epoch) # 初始化一个ndarray，包含每次epoch的cost m = X.shape[0] # 样本数量m for i in range(epoch): # 利用向量化一步求解 temp =theta - (alpha / m) * (X * theta.T - y).T * X # 以下是不用Vectorization求解梯度下降# error = (X * theta.T) - y # (97, 1) # for j in range(parameters):# term = np.multiply(error, X[:,j]) # (97, 1)# temp[0,j] = theta[0,j] - ((alpha / m) * np.sum(term)) # (1,1) theta = temp cost[i] = computeCost(X, y, theta) return theta, cost 初始化一些附加变量 - 学习速率α和要执行的迭代次数。 12alpha = 0.01epoch = 1000 现在让我们运行梯度下降算法来将我们的参数θ适合于训练集。 1final_theta, cost = gradientDescent(X, y, theta, alpha, epoch) 最后，我们可以使用我们拟合的参数计算训练模型的代价函数（误差）。 1computeCost(X, y, final_theta) 现在我们来绘制线性模型以及数据，直观地看出它的拟合。 np.linspace()在指定的间隔内返回均匀间隔的数字。 1234567891011x = np.linspace(data.Population.min(), data.Population.max(), 100) # 横坐标f = final_theta[0, 0] + (final_theta[0, 1] * x) # 纵坐标，利润fig, ax = plt.subplots(figsize=(6,4))ax.plot(x, f, 'r', label='Prediction')ax.scatter(data['Population'], data.Profit, label='Traning Data')ax.legend(loc=2) # 2表示在左上角ax.set_xlabel('Population')ax.set_ylabel('Profit')ax.set_title('Predicted Profit vs. Population Size')plt.show() 由于梯度方程式函数也在每个训练迭代中输出一个代价的向量，所以我们也可以绘制。 请注意，线性回归中的代价函数总是降低的 - 这是凸优化问题的一个例子。 123456fig, ax = plt.subplots(figsize=(8,4))ax.plot(np.arange(epoch), cost, 'r') # np.arange()返回等差数组ax.set_xlabel('Iterations')ax.set_ylabel('Cost')ax.set_title('Error vs. Training Epoch')plt.show() 多变量线性回归练习1还包括一个房屋价格数据集，其中有2个变量（房子的大小，卧室的数量）和目标（房子的价格）。 我们使用我们已经应用的技术来分析数据集。 123path = 'ex1data2.txt'data2 = pd.read_csv(path, names=['Size', 'Bedrooms', 'Price'])data2.head() 对于此任务，我们添加了另一个预处理步骤 - 特征归一化。 这个对于pandas来说很简单 12data2 = (data2 - data2.mean()) / data2.std()data2.head() 现在我们重复第1部分的预处理步骤，并对新数据集运行线性回归程序。 123456789101112131415161718# add ones columndata2.insert(0, 'Ones', 1)# set X (training data) and y (target variable)cols = data2.shape[1]X2 = data2.iloc[:,0:cols-1]y2 = data2.iloc[:,cols-1:cols]# convert to matrices and initialize thetaX2 = np.matrix(X2.values)y2 = np.matrix(y2.values)theta2 = np.matrix(np.array([0,0,0]))# perform linear regression on the data setg2, cost2 = gradientDescent(X2, y2, theta2, alpha, epoch)# get the cost (error) of the modelcomputeCost(X2, y2, g2), g2 我们也可以快速查看这一个的训练进程。 123456fig, ax = plt.subplots(figsize=(12,8))ax.plot(np.arange(epoch), cost2, 'r')ax.set_xlabel('Iterations')ax.set_ylabel('Cost')ax.set_title('Error vs. Training Epoch')plt.show() 我们也可以使用scikit-learn的线性回归函数，而不是从头开始实现这些算法。 我们将scikit-learn的线性回归算法应用于第1部分的数据，并看看它的表现。 123from sklearn import linear_modelmodel = linear_model.LinearRegression()model.fit(X, y) scikit-learn model的预测表现 1234567891011x = np.array(X[:, 1].A1)f = model.predict(X).flatten()fig, ax = plt.subplots(figsize=(8,5))ax.plot(x, f, 'r', label='Prediction')ax.scatter(data.Population, data.Profit, label='Traning Data')ax.legend(loc=2)ax.set_xlabel('Population')ax.set_ylabel('Profit')ax.set_title('Predicted Profit vs. Population Size')plt.show() normal equation（正规方程） 正规方程是通过求解下面的方程来找出使得代价函数最小的参数的：$\frac{\partial }{\partial {{\theta }_{j}}}J\left( {{\theta }_{j}} \right)=0$ 。 假设我们的训练集特征矩阵为 X（包含了${{x}_{0}}=1$）并且我们的训练集结果为向量 y，则利用正规方程解出向量 $\theta ={{\left( {{X}^{T}}X \right)}^{-1}}{{X}^{T}}y$ 。 上标T代表矩阵转置，上标-1 代表矩阵的逆。设矩阵$A={{X}^{T}}X$，则：${{\left( {{X}^{T}}X \right)}^{-1}}={{A}^{-1}}$ 梯度下降与正规方程的比较： 梯度下降：需要选择学习率α，需要多次迭代，当特征数量n大时也能较好适用，适用于各种类型的模型 正规方程：不需要选择学习率α，一次计算得出，需要计算${{\left( {{X}^{T}}X \right)}^{-1}}$，如果特征数量n较大则运算代价大，因为矩阵逆的计算时间复杂度为$O(n3)$，通常来说当$n$小于10000 时还是可以接受的，只适用于线性模型，不适合逻辑回归模型等其他模型 1234# 正规方程def normalEqn(X, y): theta = np.linalg.inv(X.T@X)@X.T@y#X.T@X等价于X.T.dot(X) return theta 12final_theta2=normalEqn(X, y)#感觉和批量梯度下降的theta的值有点差距final_theta2 1#梯度下降得到的结果是matrix([[-3.24140214, 1.1272942 ]]) 在练习2中，我们将看看分类问题的逻辑回归。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitHub Pages自定义域名如何支持https]]></title>
    <url>%2F2018%2F05%2F14%2F180514-githubpages%2F</url>
    <content type="text"><![CDATA[就在前不久，GitHub Pages开放了自定义域名支持HTTPS。这意味着广大用GitHub Pages搭建个人博客的同学们有福了，不用再自己买证书或借用第三方服务，就能开启网址左边的小绿锁啦，非常省心。详细信息点我。 最后效果如图： 设置步骤根据你的自定义域名解析类型分为两种：1. CNAME，2. A。 1 CNAME只需要在repositorys设置中开启Enforce HTTPS的选项即可。 若发现复选框为灰色开启不了，可以将Custom domain那一栏的内容删除置为空，点击save保存。再次填入你的自定义域名，点击save保存。会出现这样的提示： 说明你的证书还没发完，耐心等待即可。我等待了三天左右才成功，可能是现在申请的人太多。 2 AA记录的话只需将解析的ip指向如下四个即可，问题官方链接。 1234185.199.108.153185.199.109.153185.199.110.153185.199.111.153 其余的步骤和上面相似。 最重要的是等待，然后你就可以拥有你自己的小绿锁啦。😊]]></content>
      <categories>
        <category>Github</category>
      </categories>
      <tags>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你好，熊猫]]></title>
    <url>%2F2018%2F05%2F10%2F%E4%BD%A0%E5%A5%BD%EF%BC%8C%E7%86%8A%E7%8C%AB%2F</url>
    <content type="text"><![CDATA[哈哈]]></content>
      <categories>
        <category>日常</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
</search>
